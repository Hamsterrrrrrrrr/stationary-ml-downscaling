{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a35d3de-fd60-4775-a492-616e4d686916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "================================================================================\n",
      "XHR G6SULFUR DOWNSCALING\n",
      "================================================================================\n",
      "\n",
      "Loading data...\n",
      "Data loaded in 0.68s\n",
      "  test_input (detrended): (1020, 721, 1440)\n",
      "  test_cmip_interp: (1020, 721, 1440)\n",
      "\n",
      "------------------------------------------------------------\n",
      "Model loaded from ckpts/xhr_model.pth\n",
      "  Best val loss: 0.612789\n",
      "  Trained for 32 epochs\n",
      "\n",
      "============================================================\n",
      "RUNNING INFERENCE (G6sulfur 2015-2100)\n",
      "============================================================\n",
      "\n",
      "Normalizing input...\n",
      "\n",
      "Predicting residual...\n",
      "    Processing 0/1020...\n",
      "    Processing 100/1020...\n",
      "    Processing 200/1020...\n",
      "    Processing 300/1020...\n",
      "    Processing 400/1020...\n",
      "    Processing 500/1020...\n",
      "    Processing 600/1020...\n",
      "    Processing 700/1020...\n",
      "    Processing 800/1020...\n",
      "    Processing 900/1020...\n",
      "    Processing 1000/1020...\n",
      "    Processing 1020/1020... Done!\n",
      "\n",
      "Denormalizing predictions...\n",
      "\n",
      "Reconstructing downscaled output...\n",
      "\n",
      "Inference completed in 158.36s\n",
      "\n",
      "------------------------------------------------------------\n",
      "Saving results...\n",
      "Saved: evaluation_results_xhr/g6sulfur_downscaled_xhr.nc\n",
      "  tas_downscaled: (1020, 721, 1440)\n",
      "  tas_cmip6_interp: (1020, 721, 1440)\n",
      "  tas_residual_pred: (1020, 721, 1440)\n",
      "\n",
      "================================================================================\n",
      "COMPLETE!\n",
      "================================================================================\n",
      "Output: evaluation_results_xhr/g6sulfur_downscaled_xhr.nc\n",
      "Time range: 2015-01-16T12:00:00.000000000 to 2099-12-16T12:00:00.000000000\n",
      "Spatial resolution: 721 x 1440\n",
      "Total time: 158.36s\n"
     ]
    }
   ],
   "source": [
    "# eval_xhr.py\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from unet import UNet\n",
    "import time\n",
    "\n",
    "# ----------------------------\n",
    "# Configuration\n",
    "# ----------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "data_dir = Path(\"data\")\n",
    "ckpt_dir = Path(\"ckpts\")\n",
    "output_dir = Path(\"evaluation_results_xhr\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "model_path = ckpt_dir / \"xhr_model.pth\"\n",
    "\n",
    "# ----------------------------\n",
    "# Helper Functions\n",
    "# ----------------------------\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"Load a UNet model from checkpoint.\"\"\"\n",
    "    model = UNet(in_channels=1, out_channels=1, initial_features=32, depth=5, dropout=0.2)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "    print(f\"  Best val loss: {checkpoint['best_val_loss']:.6f}\")\n",
    "    print(f\"  Trained for {checkpoint['epoch'] + 1} epochs\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def normalize_zscore_pixel(data, mean, std):\n",
    "    \"\"\"Apply pixel-wise z-score normalization.\"\"\"\n",
    "    return (data - mean) / (std + 1e-8)\n",
    "\n",
    "\n",
    "def denormalize_zscore_pixel(data, mean, std):\n",
    "    \"\"\"Reverse pixel-wise z-score normalization.\"\"\"\n",
    "    return data * (std + 1e-8) + mean\n",
    "\n",
    "\n",
    "def predict_batched(model, data, batch_size=1):\n",
    "    \"\"\"Run model predictions in batches.\"\"\"\n",
    "    n_samples = data.shape[0]\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, n_samples, batch_size):\n",
    "            if i % 100 == 0:\n",
    "                print(f\"    Processing {i}/{n_samples}...\")\n",
    "            \n",
    "            batch = data[i:i+batch_size]\n",
    "            if batch.ndim == 3:\n",
    "                batch = np.expand_dims(batch, axis=1)\n",
    "            \n",
    "            batch_tensor = torch.tensor(batch, dtype=torch.float32).to(device)\n",
    "            batch_pred = model(batch_tensor)\n",
    "            predictions.append(batch_pred.cpu().numpy())\n",
    "    \n",
    "    print(f\"    Processing {n_samples}/{n_samples}... Done!\")\n",
    "    return np.concatenate(predictions, axis=0).squeeze(1)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Main\n",
    "# ----------------------------\n",
    "print(\"=\" * 80)\n",
    "print(\"XHR G6SULFUR DOWNSCALING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nLoading data...\")\n",
    "load_start = time.time()\n",
    "\n",
    "# Load test data (G6sulfur)\n",
    "test_input = xr.open_dataarray(data_dir / \"cmip6/g6_test_detrend_xhr.nc\")\n",
    "test_cmip_interp = xr.open_dataarray(data_dir / \"cmip6/g6_test_interp_xhr.nc\")\n",
    "\n",
    "# Load normalization stats\n",
    "with open(data_dir / \"norm_stats_xhr.pkl\", 'rb') as f:\n",
    "    norm_stats = pickle.load(f)\n",
    "\n",
    "load_time = time.time() - load_start\n",
    "print(f\"Data loaded in {load_time:.2f}s\")\n",
    "print(f\"  test_input (detrended): {test_input.shape}\")\n",
    "print(f\"  test_cmip_interp: {test_cmip_interp.shape}\")\n",
    "\n",
    "# Load model\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "model = load_model(model_path)\n",
    "\n",
    "# ----------------------------\n",
    "# Run Inference\n",
    "# ----------------------------\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RUNNING INFERENCE (G6sulfur 2015-2100)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "inference_start = time.time()\n",
    "\n",
    "# Get numpy arrays\n",
    "test_input_np = test_input.values\n",
    "test_cmip_interp_np = test_cmip_interp.values\n",
    "\n",
    "# Normalize input\n",
    "print(\"\\nNormalizing input...\")\n",
    "test_input_norm = normalize_zscore_pixel(\n",
    "    test_input_np,\n",
    "    norm_stats['input_detrend']['mean'],\n",
    "    norm_stats['input_detrend']['std']\n",
    ")\n",
    "\n",
    "# Predict residual\n",
    "print(\"\\nPredicting residual...\")\n",
    "residual_pred_norm = predict_batched(model, test_input_norm, batch_size=1)\n",
    "\n",
    "# Denormalize residual\n",
    "print(\"\\nDenormalizing predictions...\")\n",
    "residual_pred = denormalize_zscore_pixel(\n",
    "    residual_pred_norm,\n",
    "    norm_stats['residual']['mean'],\n",
    "    norm_stats['residual']['std']\n",
    ")\n",
    "\n",
    "# Reconstruct: downscaled = CMIP6_interp + predicted_residual\n",
    "print(\"\\nReconstructing downscaled output...\")\n",
    "downscaled = test_cmip_interp_np + residual_pred\n",
    "\n",
    "inference_time = time.time() - inference_start\n",
    "print(f\"\\nInference completed in {inference_time:.2f}s\")\n",
    "\n",
    "# ----------------------------\n",
    "# Save Results\n",
    "# ----------------------------\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"Saving results...\")\n",
    "\n",
    "coords = {\n",
    "    'time': test_input.time,\n",
    "    'lat': test_input.lat,\n",
    "    'lon': test_input.lon\n",
    "}\n",
    "\n",
    "ds_output = xr.Dataset({\n",
    "    'tas_downscaled': xr.DataArray(downscaled, coords=coords, dims=['time', 'lat', 'lon']),\n",
    "    'tas_cmip6_interp': xr.DataArray(test_cmip_interp_np, coords=coords, dims=['time', 'lat', 'lon']),\n",
    "    'tas_residual_pred': xr.DataArray(residual_pred, coords=coords, dims=['time', 'lat', 'lon']),\n",
    "})\n",
    "\n",
    "output_path = output_dir / \"g6sulfur_downscaled_xhr.nc\"\n",
    "ds_output.to_netcdf(output_path)\n",
    "\n",
    "print(f\"Saved: {output_path}\")\n",
    "print(f\"  tas_downscaled: {downscaled.shape}\")\n",
    "print(f\"  tas_cmip6_interp: {test_cmip_interp_np.shape}\")\n",
    "print(f\"  tas_residual_pred: {residual_pred.shape}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Summary\n",
    "# ----------------------------\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Output: {output_path}\")\n",
    "print(f\"Time range: {test_input.time.values[0]} to {test_input.time.values[-1]}\")\n",
    "print(f\"Spatial resolution: {len(coords['lat'])} x {len(coords['lon'])}\")\n",
    "print(f\"Total time: {inference_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4fb3c2-9a26-4d3f-8ffc-0802f227f61d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
