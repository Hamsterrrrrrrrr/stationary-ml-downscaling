{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf8cbce9-b8df-4dc6-ba43-2faeda600f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original datasets...\n",
      "Computing normalization statistics for training period: 1850-1980\n",
      "\n",
      "Processing pr_hr...\n",
      "  Shape check - HR: (1572, 192, 384), LR: (1572, 192, 384)\n",
      "  pr HR - Global mean: 2.373345, std: 2.978923\n",
      "  pr LR - Global mean: 2.328078, std: 2.809266\n",
      "\n",
      "Processing tas_hr...\n",
      "  Shape check - HR: (1572, 192, 384), LR: (1572, 192, 384)\n",
      "  tas HR - Global mean: 4.989362, std: 21.373560\n",
      "  tas LR - Global mean: 4.677408, std: 21.151808\n",
      "\n",
      "Processing hurs_hr...\n",
      "  Shape check - HR: (1572, 192, 384), LR: (1572, 192, 384)\n",
      "  hurs HR - Global mean: 81.109680, std: 18.955059\n",
      "  hurs LR - Global mean: 81.973465, std: 17.777142\n",
      "\n",
      "Processing sfcWind_hr...\n",
      "  Shape check - HR: (1572, 192, 384), LR: (1572, 192, 384)\n",
      "  sfcWind HR - Global mean: 6.178439, std: 2.727153\n",
      "  sfcWind LR - Global mean: 6.312948, std: 2.687389\n",
      "\n",
      "Normalization statistics computed successfully using numpy arrays!\n",
      "\n",
      "Summary of global statistics:\n",
      "pr         - HR std:   2.9789, LR std:   2.8093, Ratio: 1.06\n",
      "tas        - HR std:  21.3736, LR std:  21.1518, Ratio: 1.01\n",
      "hurs       - HR std:  18.9551, LR std:  17.7771, Ratio: 1.07\n",
      "sfcWind    - HR std:   2.7272, LR std:   2.6874, Ratio: 1.01\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Define data directory\n",
    "data_dir = \"data\"\n",
    "\n",
    "# Load the original datasets (without log transform)\n",
    "print(\"Loading original datasets...\")\n",
    "ds_hist = xr.open_dataset(f\"{data_dir}/MPI-ESM1-2-HR-LR_historical_r1i1p1f1_1850_2014_allvars.nc\")\n",
    "ds_ssp126 = xr.open_dataset(f\"{data_dir}/MPI-ESM1-2-HR-LR_ssp126_r1i1p1f1_2015_2100_allvars.nc\")\n",
    "ds_ssp245 = xr.open_dataset(f\"{data_dir}/MPI-ESM1-2-HR-LR_ssp245_r1i1p1f1_2015_2100_allvars.nc\")\n",
    "ds_ssp585 = xr.open_dataset(f\"{data_dir}/MPI-ESM1-2-HR-LR_ssp585_r1i1p1f1_2015_2100_allvars.nc\")\n",
    "\n",
    "def compute_normalization_stats(target_train_np, input_train_np):\n",
    "    \"\"\"\n",
    "    Compute all normalization statistics from training data using numpy arrays\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    target_train_np : numpy.ndarray - Training data for target (HR), shape (time, lat, lon)\n",
    "    input_train_np : numpy.ndarray - Training data for input (LR), shape (time, lat, lon)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    stats : dict with structure:\n",
    "        stats['hr']['global_mean'], stats['hr']['global_std'], etc.\n",
    "        stats['lr_interp']['global_mean'], stats['lr_interp']['global_std'], etc.\n",
    "    \"\"\"\n",
    "    stats = {\n",
    "        'hr': {},\n",
    "        'lr_interp': {}\n",
    "    }\n",
    "    \n",
    "    # HR statistics - all using numpy\n",
    "    stats['hr']['global_mean'] = float(np.mean(target_train_np))\n",
    "    stats['hr']['global_std'] = float(np.std(target_train_np))\n",
    "    stats['hr']['global_min'] = float(np.min(target_train_np))\n",
    "    stats['hr']['global_max'] = float(np.max(target_train_np))\n",
    "    stats['hr']['pixel_mean'] = np.mean(target_train_np, axis=0)  # Average over time\n",
    "    stats['hr']['pixel_std'] = np.std(target_train_np, axis=0)    # Std over time\n",
    "    stats['hr']['pixel_min'] = np.min(target_train_np, axis=0)    # Min over time\n",
    "    stats['hr']['pixel_max'] = np.max(target_train_np, axis=0)    # Max over time\n",
    "    \n",
    "    # LR_interp statistics - all using numpy\n",
    "    stats['lr_interp']['global_mean'] = float(np.mean(input_train_np))\n",
    "    stats['lr_interp']['global_std'] = float(np.std(input_train_np))\n",
    "    stats['lr_interp']['global_min'] = float(np.min(input_train_np))\n",
    "    stats['lr_interp']['global_max'] = float(np.max(input_train_np))\n",
    "    stats['lr_interp']['pixel_mean'] = np.mean(input_train_np, axis=0)  # Average over time\n",
    "    stats['lr_interp']['pixel_std'] = np.std(input_train_np, axis=0)    # Std over time\n",
    "    stats['lr_interp']['pixel_min'] = np.min(input_train_np, axis=0)    # Min over time\n",
    "    stats['lr_interp']['pixel_max'] = np.max(input_train_np, axis=0)    # Max over time\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Compute normalization statistics for all variables\n",
    "variables = ['pr_hr', 'tas_hr', 'hurs_hr', 'sfcWind_hr']\n",
    "train_start = '1850'\n",
    "train_end = '1980'\n",
    "\n",
    "print(f\"Computing normalization statistics for training period: {train_start}-{train_end}\\n\")\n",
    "\n",
    "norm_stats = {}\n",
    "for var in variables:\n",
    "    print(f\"Processing {var}...\")\n",
    "    \n",
    "    # Get base variable name (without _hr)\n",
    "    var_base = var.replace('_hr', '')\n",
    "    \n",
    "    # Get corresponding LR variable name\n",
    "    var_lr = var.replace('_hr', '_lr_interp')\n",
    "    \n",
    "    # Extract training data and IMMEDIATELY convert to numpy\n",
    "    target_train_xr = ds_hist[var].sel(time=slice(train_start, train_end))\n",
    "    input_train_xr = ds_hist[var_lr].sel(time=slice(train_start, train_end))\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    target_train_np = target_train_xr.values\n",
    "    input_train_np = input_train_xr.values\n",
    "    \n",
    "    print(f\"  Shape check - HR: {target_train_np.shape}, LR: {input_train_np.shape}\")\n",
    "    \n",
    "    # Compute statistics using numpy arrays\n",
    "    stats = compute_normalization_stats(target_train_np, input_train_np)\n",
    "    \n",
    "    # Store with base variable name\n",
    "    norm_stats[var_base] = stats\n",
    "    \n",
    "    print(f\"  {var_base} HR - Global mean: {stats['hr']['global_mean']:.6f}, std: {stats['hr']['global_std']:.6f}\")\n",
    "    print(f\"  {var_base} LR - Global mean: {stats['lr_interp']['global_mean']:.6f}, std: {stats['lr_interp']['global_std']:.6f}\")\n",
    "    print()\n",
    "\n",
    "print(\"Normalization statistics computed successfully using numpy arrays!\")\n",
    "print(\"\\nSummary of global statistics:\")\n",
    "for var_base in norm_stats.keys():\n",
    "    hr_std = norm_stats[var_base]['hr']['global_std']\n",
    "    lr_std = norm_stats[var_base]['lr_interp']['global_std']\n",
    "    ratio = hr_std / lr_std if lr_std > 0 else 0\n",
    "    print(f\"{var_base:10s} - HR std: {hr_std:8.4f}, LR std: {lr_std:8.4f}, Ratio: {ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "038d3c29-5850-47ed-88a8-803a705c0f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pr:\n",
      "  hr:\n",
      "    global_mean: 2.3733\n",
      "    global_std: 2.9789\n",
      "    global_min: 0.0000\n",
      "    global_max: 72.3470\n",
      "    pixel_mean: shape(192, 384)\n",
      "    pixel_std: shape(192, 384)\n",
      "    pixel_min: shape(192, 384)\n",
      "    pixel_max: shape(192, 384)\n",
      "  lr_interp:\n",
      "    global_mean: 2.3281\n",
      "    global_std: 2.8093\n",
      "    global_min: 0.0000\n",
      "    global_max: 48.3795\n",
      "    pixel_mean: shape(192, 384)\n",
      "    pixel_std: shape(192, 384)\n",
      "    pixel_min: shape(192, 384)\n",
      "    pixel_max: shape(192, 384)\n",
      "\n",
      "tas:\n",
      "  hr:\n",
      "    global_mean: 4.9894\n",
      "    global_std: 17.4904\n",
      "    global_min: -76.4118\n",
      "    global_max: 44.7484\n",
      "    pixel_mean: shape(192, 384)\n",
      "    pixel_std: shape(192, 384)\n",
      "    pixel_min: shape(192, 384)\n",
      "    pixel_max: shape(192, 384)\n",
      "  lr_interp:\n",
      "    global_mean: 4.6774\n",
      "    global_std: 21.1518\n",
      "    global_min: -75.3701\n",
      "    global_max: 44.2455\n",
      "    pixel_mean: shape(192, 384)\n",
      "    pixel_std: shape(192, 384)\n",
      "    pixel_min: shape(192, 384)\n",
      "    pixel_max: shape(192, 384)\n",
      "\n",
      "hurs:\n",
      "  hr:\n",
      "    global_mean: 81.1097\n",
      "    global_std: 42.0933\n",
      "    global_min: 5.0082\n",
      "    global_max: 147.1715\n",
      "    pixel_mean: shape(192, 384)\n",
      "    pixel_std: shape(192, 384)\n",
      "    pixel_min: shape(192, 384)\n",
      "    pixel_max: shape(192, 384)\n",
      "  lr_interp:\n",
      "    global_mean: 81.9735\n",
      "    global_std: 17.7771\n",
      "    global_min: 5.0062\n",
      "    global_max: 152.4052\n",
      "    pixel_mean: shape(192, 384)\n",
      "    pixel_std: shape(192, 384)\n",
      "    pixel_min: shape(192, 384)\n",
      "    pixel_max: shape(192, 384)\n",
      "\n",
      "sfcWind:\n",
      "  hr:\n",
      "    global_mean: 6.1784\n",
      "    global_std: 3.8546\n",
      "    global_min: 0.3031\n",
      "    global_max: 18.5858\n",
      "    pixel_mean: shape(192, 384)\n",
      "    pixel_std: shape(192, 384)\n",
      "    pixel_min: shape(192, 384)\n",
      "    pixel_max: shape(192, 384)\n",
      "  lr_interp:\n",
      "    global_mean: 6.3129\n",
      "    global_std: 2.6874\n",
      "    global_min: 0.2823\n",
      "    global_max: 17.8048\n",
      "    pixel_mean: shape(192, 384)\n",
      "    pixel_std: shape(192, 384)\n",
      "    pixel_min: shape(192, 384)\n",
      "    pixel_max: shape(192, 384)\n"
     ]
    }
   ],
   "source": [
    "for var in norm_stats:\n",
    "    print(f\"\\n{var}:\")\n",
    "    for res in norm_stats[var]:\n",
    "        print(f\"  {res}:\")\n",
    "        for stat in norm_stats[var][res]:\n",
    "            val = norm_stats[var][res][stat]\n",
    "            if hasattr(val, 'shape'):\n",
    "                print(f\"    {stat}: shape{val.shape}\")\n",
    "            else:\n",
    "                print(f\"    {stat}: {val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60cb7fd8-e4ea-47c4-b481-1ce9d2a7230e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving normalization statistics...\n",
      "\n",
      "Data types in norm_stats:\n",
      "  pr.hr.global_mean: <class 'float'>\n",
      "✓ Saved to data/norm_stats.pkl\n",
      "\n",
      "Verifying saved file...\n",
      "Loaded successfully!\n",
      "Variables: ['pr', 'tas', 'hurs', 'sfcWind']\n",
      "\n",
      "Example - pr HR global_mean: 2.3733\n",
      "Example - pr HR pixel_mean shape: (192, 384)\n",
      "\n",
      "✓ All checks passed!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Save normalization statistics\n",
    "print(\"Saving normalization statistics...\")\n",
    "\n",
    "# Check what we're saving\n",
    "print(\"\\nData types in norm_stats:\")\n",
    "for var in norm_stats:\n",
    "    for res in ['hr', 'lr_interp']:\n",
    "        for stat in norm_stats[var][res]:\n",
    "            val = norm_stats[var][res][stat]\n",
    "            print(f\"  {var}.{res}.{stat}: {type(val)}\")\n",
    "            break  # Just check first one\n",
    "        break\n",
    "    break\n",
    "\n",
    "# Save with pickle (pickle handles numpy arrays fine)\n",
    "with open('data/norm_stats.pkl', 'wb') as f:\n",
    "    pickle.dump(norm_stats, f)\n",
    "\n",
    "print(\"✓ Saved to data/norm_stats.pkl\")\n",
    "\n",
    "# Verify by loading it back\n",
    "print(\"\\nVerifying saved file...\")\n",
    "with open('data/norm_stats.pkl', 'rb') as f:\n",
    "    loaded_stats = pickle.load(f)\n",
    "\n",
    "# Check that it loaded correctly\n",
    "print(\"Loaded successfully!\")\n",
    "print(f\"Variables: {list(loaded_stats.keys())}\")\n",
    "print(f\"\\nExample - pr HR global_mean: {loaded_stats['pr']['hr']['global_mean']:.4f}\")\n",
    "print(f\"Example - pr HR pixel_mean shape: {loaded_stats['pr']['hr']['pixel_mean'].shape}\")\n",
    "\n",
    "# Verify numpy arrays are preserved\n",
    "assert isinstance(loaded_stats['pr']['hr']['pixel_mean'], np.ndarray), \"pixel_mean should be numpy array\"\n",
    "assert loaded_stats['pr']['hr']['pixel_mean'].shape == (192, 384), \"Shape should be preserved\"\n",
    "print(\"\\n✓ All checks passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd7cdd2-2349-4076-9658-1e43d5366228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
