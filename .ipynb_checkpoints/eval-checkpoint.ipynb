{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9076154-fafd-406a-b52d-080e98ee7006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home.ufs/yw4236/.local/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home.ufs/yw4236/.local/lib/python3.9/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from unet import UNet\n",
    "import time\n",
    "\n",
    "# ----------------------------\n",
    "# Configuration\n",
    "# ----------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "data_dir = Path(\"data\")\n",
    "ckpt_dir = Path(\"ckpts\")\n",
    "\n",
    "# Variables to evaluate\n",
    "variables = ['tas', 'pr']\n",
    "\n",
    "# Normalization methods for direct models\n",
    "normalizations = ['none', 'minmax_global', 'minmax_pixel', 'zscore_global', \n",
    "                  'zscore_pixel', 'instance_zscore', 'instance_minmax']\n",
    "\n",
    "# Input types for residual models\n",
    "residual_input_types = ['raw', 'gma', 'grid', 'gmt']\n",
    "\n",
    "# Test periods for all scenarios\n",
    "test_periods = {\n",
    "    'historical': ('2001', '2014'),\n",
    "    'ssp126': ('2015', '2100'),\n",
    "    'ssp245': ('2015', '2100'),\n",
    "    'ssp585': ('2015', '2100'),\n",
    "    'g6sulfur': ('2020', '2099')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2648d7e-d80f-4e69-937b-4b32502d5f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Loading normalization statistics...\n",
      "Direct norm stats loaded for: ['pr', 'tas', 'hurs', 'sfcWind']\n",
      "Residual norm stats loaded for: ['pr', 'tas']\n",
      "\n",
      "Datasets loaded in 0.86 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading datasets...\")\n",
    "load_start = time.time()\n",
    "\n",
    "# Original datasets (for direct models and ground truth)\n",
    "datasets_original = {\n",
    "    'historical': xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_historical_r1i1p1f1_1850_2014_allvars.nc\"),\n",
    "    'ssp126': xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_ssp126_r1i1p1f1_2015_2100_allvars.nc\"),\n",
    "    'ssp245': xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_ssp245_r1i1p1f1_2015_2100_allvars.nc\"),\n",
    "    'ssp585': xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_ssp585_r1i1p1f1_2015_2100_allvars.nc\"),\n",
    "    'g6sulfur': xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_g6sulfur_r1i1p1f1_2020_2099_allvars.nc\")\n",
    "}\n",
    "\n",
    "# Residual/detrended datasets (for residual models)\n",
    "datasets_residual = {\n",
    "    'historical': xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_historical_residual_detrended.nc\"),\n",
    "    'ssp126': xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_ssp126_residual_detrended.nc\"),\n",
    "    'ssp245': xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_ssp245_residual_detrended.nc\"),\n",
    "    'ssp585': xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_ssp585_residual_detrended.nc\"),\n",
    "    'g6sulfur': xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_g6sulfur_residual_detrended.nc\")\n",
    "}\n",
    "\n",
    "# Load normalization statistics\n",
    "print(\"Loading normalization statistics...\")\n",
    "with open(data_dir / \"norm_stats.pkl\", 'rb') as f:\n",
    "    norm_stats_direct = pickle.load(f)\n",
    "\n",
    "with open(data_dir / \"norm_stats_zscore_pixel_residual_detrended.pkl\", 'rb') as f:\n",
    "    norm_stats_residual = pickle.load(f)\n",
    "\n",
    "load_time = time.time() - load_start\n",
    "print(f\"Direct norm stats loaded for: {list(norm_stats_direct.keys())}\")\n",
    "print(f\"Residual norm stats loaded for: {list(norm_stats_residual.keys())}\")\n",
    "print(f\"\\nDatasets loaded in {load_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c11fd43e-bde8-4606-be0d-6923cba311a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Helper Functions\n",
    "\n",
    "def apply_normalization(data, method, norm_stats, var, resolution='lr_interp'):\n",
    "    \"\"\"Apply normalization method to data.\"\"\"\n",
    "    data_np = data.values if hasattr(data, 'values') else data\n",
    "    \n",
    "    if method == 'none':\n",
    "        return data_np\n",
    "    elif method == 'minmax_global':\n",
    "        data_min = norm_stats[var][resolution]['global_min']\n",
    "        data_max = norm_stats[var][resolution]['global_max']\n",
    "        return 2 * (data_np - data_min) / (data_max - data_min + 1e-8) - 1\n",
    "    elif method == 'minmax_pixel':\n",
    "        data_min = norm_stats[var][resolution]['pixel_min']\n",
    "        data_max = norm_stats[var][resolution]['pixel_max']\n",
    "        return 2 * (data_np - data_min) / (data_max - data_min + 1e-8) - 1\n",
    "    elif method == 'zscore_global':\n",
    "        data_mean = norm_stats[var][resolution]['global_mean']\n",
    "        data_std = norm_stats[var][resolution]['global_std']\n",
    "        return (data_np - data_mean) / (data_std + 1e-8)\n",
    "    elif method == 'zscore_pixel':\n",
    "        data_mean = norm_stats[var][resolution]['pixel_mean']\n",
    "        data_std = norm_stats[var][resolution]['pixel_std']\n",
    "        return (data_np - data_mean) / (data_std + 1e-8)\n",
    "    elif method == 'instance_zscore':\n",
    "        data_mean = np.mean(data_np, axis=(1, 2), keepdims=True)\n",
    "        data_std = np.std(data_np, axis=(1, 2), keepdims=True)\n",
    "        return (data_np - data_mean) / (data_std + 1e-8)\n",
    "    elif method == 'instance_minmax':\n",
    "        data_min = np.min(data_np, axis=(1, 2), keepdims=True)\n",
    "        data_max = np.max(data_np, axis=(1, 2), keepdims=True)\n",
    "        return 2 * (data_np - data_min) / (data_max - data_min + 1e-8) - 1\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown normalization method: {method}\")\n",
    "\n",
    "\n",
    "def denormalize_predictions(predictions, method, norm_stats, var, input_data=None):\n",
    "    \"\"\"Denormalize predictions back to original scale.\"\"\"\n",
    "    if method == 'none':\n",
    "        return predictions\n",
    "    elif method == 'minmax_global':\n",
    "        hr_min = norm_stats[var]['hr']['global_min']\n",
    "        hr_max = norm_stats[var]['hr']['global_max']\n",
    "        return ((predictions + 1) / 2) * (hr_max - hr_min) + hr_min\n",
    "    elif method == 'minmax_pixel':\n",
    "        hr_min = norm_stats[var]['hr']['pixel_min']\n",
    "        hr_max = norm_stats[var]['hr']['pixel_max']\n",
    "        return ((predictions + 1) / 2) * (hr_max - hr_min) + hr_min\n",
    "    elif method == 'zscore_global':\n",
    "        hr_mean = norm_stats[var]['hr']['global_mean']\n",
    "        hr_std = norm_stats[var]['hr']['global_std']\n",
    "        return predictions * hr_std + hr_mean\n",
    "    elif method == 'zscore_pixel':\n",
    "        hr_mean = norm_stats[var]['hr']['pixel_mean']\n",
    "        hr_std = norm_stats[var]['hr']['pixel_std']\n",
    "        return predictions * hr_std + hr_mean\n",
    "    elif method == 'instance_zscore':\n",
    "        input_mean = np.mean(input_data, axis=(1, 2), keepdims=True)\n",
    "        input_std = np.std(input_data, axis=(1, 2), keepdims=True)\n",
    "        return predictions * input_std + input_mean\n",
    "    elif method == 'instance_minmax':\n",
    "        input_min = np.min(input_data, axis=(1, 2), keepdims=True)\n",
    "        input_max = np.max(input_data, axis=(1, 2), keepdims=True)\n",
    "        return ((predictions + 1) / 2) * (input_max - input_min) + input_min\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown normalization method: {method}\")\n",
    "\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"Load a UNet model from checkpoint.\"\"\"\n",
    "    model = UNet(in_channels=1, out_channels=1, initial_features=32, depth=5, dropout=0.2)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_batched(model, data, batch_size=32):\n",
    "    \"\"\"Run model predictions in batches.\"\"\"\n",
    "    n_samples = len(data)\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, n_samples, batch_size):\n",
    "            batch = data[i:i+batch_size]\n",
    "            batch_tensor = torch.tensor(batch, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "            batch_pred = model(batch_tensor)\n",
    "            predictions.append(batch_pred.cpu().numpy())\n",
    "    \n",
    "    return np.concatenate(predictions, axis=0).squeeze(1)\n",
    "\n",
    "\n",
    "print(\"Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1c50850-5956-4f5f-b976-25e93243ffb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Evaluation Functions\n",
    "\n",
    "def evaluate_direct_models(var, scenario_name, dataset, test_period, timing_results):\n",
    "    \"\"\"Evaluate all direct (normalization-based) models for a variable and scenario.\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    var_lr = f'{var}_lr_interp'\n",
    "    var_hr = f'{var}_hr'\n",
    "    \n",
    "    # Extract data\n",
    "    lr_data_xr = dataset[var_lr].sel(time=slice(test_period[0], test_period[1]))\n",
    "    hr_data_xr = dataset[var_hr].sel(time=slice(test_period[0], test_period[1]))\n",
    "    \n",
    "    lr_data_raw = lr_data_xr.values\n",
    "    \n",
    "    # Store coordinates\n",
    "    coords = {\n",
    "        'time': hr_data_xr.time,\n",
    "        'lat': hr_data_xr.lat,\n",
    "        'lon': hr_data_xr.lon\n",
    "    }\n",
    "    \n",
    "    # Store ground truth and input\n",
    "    results['groundtruth'] = hr_data_xr\n",
    "    results['input'] = lr_data_xr\n",
    "    \n",
    "    # Evaluate each normalization method\n",
    "    for norm_method in normalizations:\n",
    "        model_path = ckpt_dir / f\"{var}_{norm_method}.pth\"\n",
    "        \n",
    "        if not model_path.exists():\n",
    "            print(f\"        Model not found: {model_path}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            model_start = time.time()\n",
    "            \n",
    "            # Load model\n",
    "            model = load_model(model_path)\n",
    "            \n",
    "            # Normalize input\n",
    "            lr_data_norm = apply_normalization(lr_data_xr, norm_method, norm_stats_direct, var)\n",
    "            \n",
    "            # Predict\n",
    "            predictions = predict_batched(model, lr_data_norm)\n",
    "            \n",
    "            # Denormalize\n",
    "            predictions_denorm = denormalize_predictions(\n",
    "                predictions, norm_method, norm_stats_direct, var, lr_data_raw\n",
    "            )\n",
    "            \n",
    "            # Create DataArray\n",
    "            pred_da = xr.DataArray(\n",
    "                predictions_denorm,\n",
    "                coords=coords,\n",
    "                dims=['time', 'lat', 'lon']\n",
    "            )\n",
    "            \n",
    "            results[f'pred_{norm_method}'] = pred_da\n",
    "            \n",
    "            model_time = time.time() - model_start\n",
    "            timing_results['direct'][var][scenario_name][norm_method] = model_time\n",
    "            print(f\"        {norm_method}: {model_time:.2f}s\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"        {norm_method}: Error - {e}\")\n",
    "            continue\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def evaluate_residual_models(var, scenario_name, dataset_residual, dataset_original, test_period, timing_results):\n",
    "    \"\"\"Evaluate all residual models for a variable and scenario.\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    var_lr = f'{var}_lr_interp'\n",
    "    var_hr = f'{var}_hr'\n",
    "    \n",
    "    # Extract original data\n",
    "    lr_original = dataset_original[var_lr].sel(time=slice(test_period[0], test_period[1]))\n",
    "    hr_original = dataset_original[var_hr].sel(time=slice(test_period[0], test_period[1]))\n",
    "    \n",
    "    # Store coordinates\n",
    "    coords = {\n",
    "        'time': hr_original.time,\n",
    "        'lat': hr_original.lat,\n",
    "        'lon': hr_original.lon\n",
    "    }\n",
    "    \n",
    "    # Store ground truth and input\n",
    "    results['groundtruth'] = hr_original\n",
    "    results['input'] = lr_original\n",
    "    \n",
    "    lr_original_np = lr_original.values\n",
    "    \n",
    "    # Evaluate each input type\n",
    "    for input_type in residual_input_types:\n",
    "        # Determine input variable and key\n",
    "        if input_type == 'raw':\n",
    "            input_var = f\"{var}_lr_interp\"\n",
    "            input_key = 'lr_interp'\n",
    "            model_filename = f\"{var}_lr_to_residual.pth\"\n",
    "        else:\n",
    "            detrend_map = {'gma': 'detrend_gma', 'grid': 'detrend_grid', 'gmt': 'detrend_gmt'}\n",
    "            input_var = f\"{var}_lr_{detrend_map[input_type]}\"\n",
    "            input_key = f'lr_{detrend_map[input_type]}'\n",
    "            model_filename = f\"{var}_lr_{input_type}_to_residual.pth\"\n",
    "        \n",
    "        model_path = ckpt_dir / model_filename\n",
    "        \n",
    "        if not model_path.exists():\n",
    "            print(f\"        Model not found: {model_path}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            model_start = time.time()\n",
    "            \n",
    "            # Load model\n",
    "            model = load_model(model_path)\n",
    "            \n",
    "            # Get input data\n",
    "            lr_data = dataset_residual[input_var].sel(time=slice(test_period[0], test_period[1])).values\n",
    "            \n",
    "            # Apply zscore_pixel normalization\n",
    "            lr_mean = norm_stats_residual[var][input_key]['pixel_mean']\n",
    "            lr_std = norm_stats_residual[var][input_key]['pixel_std']\n",
    "            lr_normalized = (lr_data - lr_mean) / (lr_std + 1e-8)\n",
    "            \n",
    "            # Predict\n",
    "            predictions_norm = predict_batched(model, lr_normalized)\n",
    "            \n",
    "            # Denormalize residual predictions\n",
    "            residual_mean = norm_stats_residual[var]['residual']['pixel_mean']\n",
    "            residual_std = norm_stats_residual[var]['residual']['pixel_std']\n",
    "            residual_pred = predictions_norm * residual_std + residual_mean\n",
    "            \n",
    "            # Reconstruct full HR prediction\n",
    "            hr_pred = residual_pred + lr_original_np\n",
    "            \n",
    "            # Create DataArray\n",
    "            pred_da = xr.DataArray(\n",
    "                hr_pred,\n",
    "                coords=coords,\n",
    "                dims=['time', 'lat', 'lon']\n",
    "            )\n",
    "            \n",
    "            results[f'pred_{input_type}'] = pred_da\n",
    "            \n",
    "            model_time = time.time() - model_start\n",
    "            timing_results['residual'][var][scenario_name][input_type] = model_time\n",
    "            print(f\"        {input_type}: {model_time:.2f}s\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"        {input_type}: Error - {e}\")\n",
    "            continue\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"Evaluation functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e708fc0f-3de6-48de-aa96-0740993114e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EVALUATING DIRECT MODELS\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "Variable: TAS\n",
      "============================================================\n",
      "\n",
      "    Scenario: historical\n",
      "    ----------------------------------------\n",
      "        none: 1.15s\n",
      "        minmax_global: 1.24s\n",
      "        minmax_pixel: 1.61s\n",
      "        zscore_global: 1.41s\n",
      "        zscore_pixel: 1.46s\n",
      "        instance_zscore: 1.70s\n",
      "        instance_minmax: 1.59s\n",
      "    Scenario total: 10.99s | Saved: evaluation_results/tas_evaluation_historical.nc\n",
      "\n",
      "    Scenario: ssp126\n",
      "    ----------------------------------------\n",
      "        none: 4.59s\n",
      "        minmax_global: 5.12s\n",
      "        minmax_pixel: 5.94s\n",
      "        zscore_global: 5.12s\n",
      "        zscore_pixel: 5.49s\n",
      "        instance_zscore: 7.02s\n",
      "        instance_minmax: 6.07s\n",
      "    Scenario total: 43.23s | Saved: evaluation_results/tas_evaluation_ssp126.nc\n",
      "\n",
      "    Scenario: ssp245\n",
      "    ----------------------------------------\n",
      "        none: 3.85s\n",
      "        minmax_global: 4.68s\n",
      "        minmax_pixel: 5.31s\n",
      "        zscore_global: 4.67s\n",
      "        zscore_pixel: 5.29s\n",
      "        instance_zscore: 7.69s\n",
      "        instance_minmax: 6.08s\n",
      "    Scenario total: 41.84s | Saved: evaluation_results/tas_evaluation_ssp245.nc\n",
      "\n",
      "    Scenario: ssp585\n",
      "    ----------------------------------------\n",
      "        none: 4.32s\n",
      "        minmax_global: 4.71s\n",
      "        minmax_pixel: 5.83s\n",
      "        zscore_global: 4.80s\n",
      "        zscore_pixel: 5.10s\n",
      "        instance_zscore: 6.73s\n",
      "        instance_minmax: 6.23s\n",
      "    Scenario total: 41.73s | Saved: evaluation_results/tas_evaluation_ssp585.nc\n",
      "\n",
      "    Scenario: g6sulfur\n",
      "    ----------------------------------------\n",
      "        none: 3.52s\n",
      "        minmax_global: 4.32s\n",
      "        minmax_pixel: 4.89s\n",
      "        zscore_global: 4.40s\n",
      "        zscore_pixel: 4.90s\n",
      "        instance_zscore: 6.58s\n",
      "        instance_minmax: 5.74s\n",
      "    Scenario total: 38.07s | Saved: evaluation_results/tas_evaluation_g6sulfur.nc\n",
      "\n",
      "============================================================\n",
      "Variable: PR\n",
      "============================================================\n",
      "\n",
      "    Scenario: historical\n",
      "    ----------------------------------------\n",
      "        none: 1.05s\n",
      "        minmax_global: 1.28s\n",
      "        minmax_pixel: 1.41s\n",
      "        zscore_global: 1.20s\n",
      "        zscore_pixel: 1.40s\n",
      "        instance_zscore: 1.62s\n",
      "        instance_minmax: 1.42s\n",
      "    Scenario total: 10.42s | Saved: evaluation_results/pr_evaluation_historical.nc\n",
      "\n",
      "    Scenario: ssp126\n",
      "    ----------------------------------------\n",
      "        none: 4.24s\n",
      "        minmax_global: 5.42s\n",
      "        minmax_pixel: 6.10s\n",
      "        zscore_global: 4.91s\n",
      "        zscore_pixel: 5.71s\n",
      "        instance_zscore: 7.15s\n",
      "        instance_minmax: 6.17s\n",
      "    Scenario total: 44.74s | Saved: evaluation_results/pr_evaluation_ssp126.nc\n",
      "\n",
      "    Scenario: ssp245\n",
      "    ----------------------------------------\n",
      "        none: 4.30s\n",
      "        minmax_global: 4.48s\n",
      "        minmax_pixel: 5.73s\n",
      "        zscore_global: 4.62s\n",
      "        zscore_pixel: 5.34s\n",
      "        instance_zscore: 7.04s\n",
      "        instance_minmax: 6.80s\n",
      "    Scenario total: 43.64s | Saved: evaluation_results/pr_evaluation_ssp245.nc\n",
      "\n",
      "    Scenario: ssp585\n",
      "    ----------------------------------------\n",
      "        none: 4.01s\n",
      "        minmax_global: 4.90s\n",
      "        minmax_pixel: 5.87s\n",
      "        zscore_global: 5.09s\n",
      "        zscore_pixel: 5.68s\n",
      "        instance_zscore: 6.95s\n",
      "        instance_minmax: 5.96s\n",
      "    Scenario total: 43.82s | Saved: evaluation_results/pr_evaluation_ssp585.nc\n",
      "\n",
      "    Scenario: g6sulfur\n",
      "    ----------------------------------------\n",
      "        none: 3.77s\n",
      "        minmax_global: 4.34s\n",
      "        minmax_pixel: 5.66s\n",
      "        zscore_global: 4.79s\n",
      "        zscore_pixel: 5.69s\n",
      "        instance_zscore: 6.39s\n",
      "        instance_minmax: 6.00s\n",
      "    Scenario total: 41.34s | Saved: evaluation_results/pr_evaluation_g6sulfur.nc\n",
      "\n",
      "============================================================\n",
      "Direct evaluation complete! Total time: 359.82s (6.00 min)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"EVALUATING DIRECT MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize timing results\n",
    "timing_results = {\n",
    "    'direct': {var: {scen: {} for scen in test_periods.keys()} for var in variables},\n",
    "    'residual': {var: {scen: {} for scen in test_periods.keys()} for var in variables}\n",
    "}\n",
    "\n",
    "output_dir_direct = Path(\"evaluation_results\")\n",
    "output_dir_direct.mkdir(exist_ok=True)\n",
    "\n",
    "total_start = time.time()\n",
    "\n",
    "for var in variables:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Variable: {var.upper()}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for scenario_name in test_periods.keys():\n",
    "        print(f\"\\n    Scenario: {scenario_name}\")\n",
    "        print(f\"    {'-'*40}\")\n",
    "        \n",
    "        test_period = test_periods[scenario_name]\n",
    "        scenario_start = time.time()\n",
    "        \n",
    "        try:\n",
    "            results = evaluate_direct_models(\n",
    "                var, scenario_name, \n",
    "                datasets_original[scenario_name], \n",
    "                test_period,\n",
    "                timing_results\n",
    "            )\n",
    "            \n",
    "            # Save results\n",
    "            ds_result = xr.Dataset()\n",
    "            for key, value in results.items():\n",
    "                ds_result[key] = value\n",
    "            \n",
    "            output_path = output_dir_direct / f\"{var}_evaluation_{scenario_name}.nc\"\n",
    "            ds_result.to_netcdf(output_path)\n",
    "            \n",
    "            scenario_time = time.time() - scenario_start\n",
    "            print(f\"    Scenario total: {scenario_time:.2f}s | Saved: {output_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    Error processing {scenario_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "direct_total_time = time.time() - total_start\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Direct evaluation complete! Total time: {direct_total_time:.2f}s ({direct_total_time/60:.2f} min)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29d8491e-7fde-427e-b603-cd485da86d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EVALUATING RESIDUAL MODELS\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "Variable: TAS\n",
      "============================================================\n",
      "\n",
      "    Scenario: historical\n",
      "    ----------------------------------------\n",
      "        raw: 1.41s\n",
      "        gma: 1.51s\n",
      "        grid: 1.59s\n",
      "        gmt: 1.54s\n",
      "    Scenario total: 6.93s | Saved: evaluation_results_residual/tas_evaluation_historical.nc\n",
      "\n",
      "    Scenario: ssp126\n",
      "    ----------------------------------------\n",
      "        raw: 6.12s\n",
      "        gma: 6.66s\n",
      "        grid: 6.90s\n",
      "        gmt: 6.47s\n",
      "    Scenario total: 31.14s | Saved: evaluation_results_residual/tas_evaluation_ssp126.nc\n",
      "\n",
      "    Scenario: ssp245\n",
      "    ----------------------------------------\n",
      "        raw: 6.66s\n",
      "        gma: 6.74s\n",
      "        grid: 7.12s\n",
      "        gmt: 6.93s\n",
      "    Scenario total: 33.59s | Saved: evaluation_results_residual/tas_evaluation_ssp245.nc\n",
      "\n",
      "    Scenario: ssp585\n",
      "    ----------------------------------------\n",
      "        raw: 7.28s\n",
      "        gma: 6.99s\n",
      "        grid: 6.75s\n",
      "        gmt: 6.40s\n",
      "    Scenario total: 32.45s | Saved: evaluation_results_residual/tas_evaluation_ssp585.nc\n",
      "\n",
      "    Scenario: g6sulfur\n",
      "    ----------------------------------------\n",
      "        raw: 5.53s\n",
      "        gma: 5.73s\n",
      "        grid: 5.70s\n",
      "        gmt: 6.06s\n",
      "    Scenario total: 27.72s | Saved: evaluation_results_residual/tas_evaluation_g6sulfur.nc\n",
      "\n",
      "============================================================\n",
      "Variable: PR\n",
      "============================================================\n",
      "\n",
      "    Scenario: historical\n",
      "    ----------------------------------------\n",
      "        raw: 1.38s\n",
      "        gma: 1.47s\n",
      "        grid: 1.40s\n",
      "        gmt: 1.52s\n",
      "    Scenario total: 6.80s | Saved: evaluation_results_residual/pr_evaluation_historical.nc\n",
      "\n",
      "    Scenario: ssp126\n",
      "    ----------------------------------------\n",
      "        raw: 6.22s\n",
      "        gma: 6.63s\n",
      "        grid: 6.77s\n",
      "        gmt: 6.16s\n",
      "    Scenario total: 30.98s | Saved: evaluation_results_residual/pr_evaluation_ssp126.nc\n",
      "\n",
      "    Scenario: ssp245\n",
      "    ----------------------------------------\n",
      "        raw: 6.18s\n",
      "        gma: 6.24s\n",
      "        grid: 6.31s\n",
      "        gmt: 6.47s\n",
      "    Scenario total: 30.85s | Saved: evaluation_results_residual/pr_evaluation_ssp245.nc\n",
      "\n",
      "    Scenario: ssp585\n",
      "    ----------------------------------------\n",
      "        raw: 6.43s\n",
      "        gma: 6.85s\n",
      "        grid: 7.21s\n",
      "        gmt: 7.27s\n",
      "    Scenario total: 34.49s | Saved: evaluation_results_residual/pr_evaluation_ssp585.nc\n",
      "\n",
      "    Scenario: g6sulfur\n",
      "    ----------------------------------------\n",
      "        raw: Error - \"No variable named 'pr_lr_interp'. Variables on the dataset include ['tas_hr', 'tas_lr_interp', 'tas_residual', 'tas_lr_detrend_gma', 'tas_lr_detrend_grid', 'tas_lr_detrend_gmt', 'time', 'lat', 'lon']\"\n",
      "        gma: Error - \"No variable named 'pr_lr_detrend_gma'. Variables on the dataset include ['tas_hr', 'tas_lr_interp', 'tas_residual', 'tas_lr_detrend_gma', 'tas_lr_detrend_grid', 'tas_lr_detrend_gmt', 'time', 'lat', 'lon']\"\n",
      "        grid: Error - \"No variable named 'pr_lr_detrend_grid'. Variables on the dataset include ['tas_hr', 'tas_lr_interp', 'tas_residual', 'tas_lr_detrend_gma', 'tas_lr_detrend_grid', 'tas_lr_detrend_gmt', 'time', 'lat', 'lon']\"\n",
      "        gmt: Error - \"No variable named 'pr_lr_detrend_gmt'. Variables on the dataset include ['tas_hr', 'tas_lr_interp', 'tas_residual', 'tas_lr_detrend_gma', 'tas_lr_detrend_grid', 'tas_lr_detrend_gmt', 'time', 'lat', 'lon']\"\n",
      "    Scenario total: 4.02s | Saved: evaluation_results_residual/pr_evaluation_g6sulfur.nc\n",
      "\n",
      "============================================================\n",
      "Residual evaluation complete! Total time: 238.96s (3.98 min)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"EVALUATING RESIDUAL MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "output_dir_residual = Path(\"evaluation_results_residual\")\n",
    "output_dir_residual.mkdir(exist_ok=True)\n",
    "\n",
    "total_start = time.time()\n",
    "\n",
    "for var in variables:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Variable: {var.upper()}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for scenario_name in test_periods.keys():\n",
    "        print(f\"\\n    Scenario: {scenario_name}\")\n",
    "        print(f\"    {'-'*40}\")\n",
    "        \n",
    "        test_period = test_periods[scenario_name]\n",
    "        scenario_start = time.time()\n",
    "        \n",
    "        try:\n",
    "            results = evaluate_residual_models(\n",
    "                var, scenario_name,\n",
    "                datasets_residual[scenario_name],\n",
    "                datasets_original[scenario_name],\n",
    "                test_period,\n",
    "                timing_results\n",
    "            )\n",
    "            \n",
    "            # Save results\n",
    "            ds_result = xr.Dataset()\n",
    "            for key, value in results.items():\n",
    "                ds_result[key] = value\n",
    "            \n",
    "            output_path = output_dir_residual / f\"{var}_evaluation_{scenario_name}.nc\"\n",
    "            ds_result.to_netcdf(output_path)\n",
    "            \n",
    "            scenario_time = time.time() - scenario_start\n",
    "            print(f\"    Scenario total: {scenario_time:.2f}s | Saved: {output_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    Error processing {scenario_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "residual_total_time = time.time() - total_start\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Residual evaluation complete! Total time: {residual_total_time:.2f}s ({residual_total_time/60:.2f} min)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99d41ba1-59c8-4e76-8bb9-78b65dcb26ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RE-EVALUATING RESIDUAL MODELS FOR G6SULFUR\n",
      "============================================================\n",
      "\n",
      "  Variable: tas\n",
      "  ----------------------------------------\n",
      "        raw: 6.10s\n",
      "        gma: 6.23s\n",
      "        grid: 6.18s\n",
      "        gmt: 6.24s\n",
      "  Saved: evaluation_results_residual/tas_evaluation_g6sulfur.nc (29.03s)\n",
      "\n",
      "  Variable: pr\n",
      "  ----------------------------------------\n",
      "        raw: 6.15s\n",
      "        gma: 5.98s\n",
      "        grid: 6.84s\n",
      "        gmt: 6.57s\n",
      "  Saved: evaluation_results_residual/pr_evaluation_g6sulfur.nc (30.59s)\n",
      "\n",
      "============================================================\n",
      "G6sulfur residual evaluation complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell: Re-run residual evaluation for g6sulfur ONLY\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RE-EVALUATING RESIDUAL MODELS FOR G6SULFUR\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Reload the updated g6sulfur residual dataset\n",
    "datasets_residual['g6sulfur'] = xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_g6sulfur_residual_detrended.nc\")\n",
    "\n",
    "scenario_name = 'g6sulfur'\n",
    "test_period = test_periods[scenario_name]\n",
    "\n",
    "for var in variables:\n",
    "    print(f\"\\n  Variable: {var}\")\n",
    "    print(f\"  {'-'*40}\")\n",
    "    \n",
    "    scenario_start = time.time()\n",
    "    \n",
    "    results = evaluate_residual_models(\n",
    "        var, scenario_name,\n",
    "        datasets_residual[scenario_name],\n",
    "        datasets_original[scenario_name],\n",
    "        test_period,\n",
    "        timing_results\n",
    "    )\n",
    "    \n",
    "    # Save results\n",
    "    ds_result = xr.Dataset()\n",
    "    for key, value in results.items():\n",
    "        ds_result[key] = value\n",
    "    \n",
    "    output_path = output_dir_residual / f\"{var}_evaluation_{scenario_name}.nc\"\n",
    "    ds_result.to_netcdf(output_path)\n",
    "    \n",
    "    scenario_time = time.time() - scenario_start\n",
    "    print(f\"  Saved: {output_path} ({scenario_time:.2f}s)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"G6sulfur residual evaluation complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69db6d45-4481-4496-b3d5-e2c00189b871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TIMING SUMMARY\n",
      "================================================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "DIRECT MODELS\n",
      "------------------------------------------------------------\n",
      "\n",
      "TAS:\n",
      "Scenario        none       minmax_g   minmax_p   zscore_g   zscore_p   instance   instance  \n",
      "-------------------------------------------------------------------------------------\n",
      "historical      1.15       1.24       1.61       1.41       1.46       1.70       1.59       \n",
      "ssp126          4.59       5.12       5.94       5.12       5.49       7.02       6.07       \n",
      "ssp245          3.85       4.68       5.31       4.67       5.29       7.69       6.08       \n",
      "ssp585          4.32       4.71       5.83       4.80       5.10       6.73       6.23       \n",
      "g6sulfur        3.52       4.32       4.89       4.40       4.90       6.58       5.74       \n",
      "-------------------------------------------------------------------------------------\n",
      "TOTAL           17.44      20.07      23.58      20.39      22.24      29.72      25.71      \n",
      "\n",
      "PR:\n",
      "Scenario        none       minmax_g   minmax_p   zscore_g   zscore_p   instance   instance  \n",
      "-------------------------------------------------------------------------------------\n",
      "historical      1.05       1.28       1.41       1.20       1.40       1.62       1.42       \n",
      "ssp126          4.24       5.42       6.10       4.91       5.71       7.15       6.17       \n",
      "ssp245          4.30       4.48       5.73       4.62       5.34       7.04       6.80       \n",
      "ssp585          4.01       4.90       5.87       5.09       5.68       6.95       5.96       \n",
      "g6sulfur        3.77       4.34       5.66       4.79       5.69       6.39       6.00       \n",
      "-------------------------------------------------------------------------------------\n",
      "TOTAL           17.38      20.43      24.76      20.60      23.82      29.16      26.35      \n",
      "\n",
      "------------------------------------------------------------\n",
      "RESIDUAL MODELS\n",
      "------------------------------------------------------------\n",
      "\n",
      "TAS:\n",
      "Scenario        raw        gma        grid       gmt       \n",
      "-------------------------------------------------------\n",
      "historical      1.41       1.51       1.59       1.54       \n",
      "ssp126          6.12       6.66       6.90       6.47       \n",
      "ssp245          6.66       6.74       7.12       6.93       \n",
      "ssp585          7.28       6.99       6.75       6.40       \n",
      "g6sulfur        5.53       5.73       5.70       6.06       \n",
      "-------------------------------------------------------\n",
      "TOTAL           26.99      27.63      28.06      27.40      \n",
      "\n",
      "PR:\n",
      "Scenario        raw        gma        grid       gmt       \n",
      "-------------------------------------------------------\n",
      "historical      1.38       1.47       1.40       1.52       \n",
      "ssp126          6.22       6.63       6.77       6.16       \n",
      "ssp245          6.18       6.24       6.31       6.47       \n",
      "ssp585          6.43       6.85       7.21       7.27       \n",
      "g6sulfur        N/A        N/A        N/A        N/A        \n",
      "-------------------------------------------------------\n",
      "TOTAL           20.21      21.18      21.69      21.42      \n",
      "\n",
      "============================================================\n",
      "Direct models total:       321.66s (5.36 min)\n",
      "Residual models total:     194.58s (3.24 min)\n",
      "========================================\n",
      "GRAND TOTAL:               516.23s (8.60 min)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Print Timing Summary\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TIMING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Direct Models Summary\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"DIRECT MODELS\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for var in variables:\n",
    "    print(f\"\\n{var.upper()}:\")\n",
    "    print(f\"{'Scenario':<15} \" + \" \".join([f\"{n[:8]:<10}\" for n in normalizations]))\n",
    "    print(\"-\" * (15 + 10 * len(normalizations)))\n",
    "    \n",
    "    for scenario_name in test_periods.keys():\n",
    "        row = f\"{scenario_name:<15} \"\n",
    "        for norm in normalizations:\n",
    "            if norm in timing_results['direct'][var][scenario_name]:\n",
    "                t = timing_results['direct'][var][scenario_name][norm]\n",
    "                row += f\"{t:<10.2f} \"\n",
    "            else:\n",
    "                row += f\"{'N/A':<10} \"\n",
    "        print(row)\n",
    "    \n",
    "    # Calculate totals per normalization\n",
    "    print(\"-\" * (15 + 10 * len(normalizations)))\n",
    "    row = f\"{'TOTAL':<15} \"\n",
    "    for norm in normalizations:\n",
    "        total = sum(timing_results['direct'][var][scen].get(norm, 0) for scen in test_periods.keys())\n",
    "        row += f\"{total:<10.2f} \"\n",
    "    print(row)\n",
    "\n",
    "# Residual Models Summary\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"RESIDUAL MODELS\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for var in variables:\n",
    "    print(f\"\\n{var.upper()}:\")\n",
    "    print(f\"{'Scenario':<15} \" + \" \".join([f\"{t:<10}\" for t in residual_input_types]))\n",
    "    print(\"-\" * (15 + 10 * len(residual_input_types)))\n",
    "    \n",
    "    for scenario_name in test_periods.keys():\n",
    "        row = f\"{scenario_name:<15} \"\n",
    "        for input_type in residual_input_types:\n",
    "            if input_type in timing_results['residual'][var][scenario_name]:\n",
    "                t = timing_results['residual'][var][scenario_name][input_type]\n",
    "                row += f\"{t:<10.2f} \"\n",
    "            else:\n",
    "                row += f\"{'N/A':<10} \"\n",
    "        print(row)\n",
    "    \n",
    "    # Calculate totals per input type\n",
    "    print(\"-\" * (15 + 10 * len(residual_input_types)))\n",
    "    row = f\"{'TOTAL':<15} \"\n",
    "    for input_type in residual_input_types:\n",
    "        total = sum(timing_results['residual'][var][scen].get(input_type, 0) for scen in test_periods.keys())\n",
    "        row += f\"{total:<10.2f} \"\n",
    "    print(row)\n",
    "\n",
    "# Grand Total\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "direct_total = sum(\n",
    "    timing_results['direct'][var][scen].get(norm, 0)\n",
    "    for var in variables\n",
    "    for scen in test_periods.keys()\n",
    "    for norm in normalizations\n",
    ")\n",
    "residual_total = sum(\n",
    "    timing_results['residual'][var][scen].get(input_type, 0)\n",
    "    for var in variables\n",
    "    for scen in test_periods.keys()\n",
    "    for input_type in residual_input_types\n",
    ")\n",
    "grand_total = direct_total + residual_total\n",
    "\n",
    "print(f\"Direct models total:   {direct_total:>10.2f}s ({direct_total/60:.2f} min)\")\n",
    "print(f\"Residual models total: {residual_total:>10.2f}s ({residual_total/60:.2f} min)\")\n",
    "print(f\"{'='*40}\")\n",
    "print(f\"GRAND TOTAL:           {grand_total:>10.2f}s ({grand_total/60:.2f} min)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f0a4d3-43cf-477b-9fed-a10cbb2aa31b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
