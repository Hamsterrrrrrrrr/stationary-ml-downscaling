{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48c4ea56-1374-4cbc-bfd1-1d47585ed88a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Relative Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad1941f-2905-4f6b-a31a-febefe6dd25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home.ufs/yw4236/.local/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home.ufs/yw4236/.local/lib/python3.9/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Loading normalization statistics...\n",
      "Normalization stats loaded for variables: ['pr', 'tas', 'hurs', 'sfcWind']\n",
      "\n",
      "================================================================================\n",
      "EVALUATING RELATIVE HUMIDITY (HURS) MODELS\n",
      "================================================================================\n",
      "\n",
      "HISTORICAL Scenario\n",
      "----------------------------------------\n",
      "    Evaluating none...\n",
      "Success\n",
      "    Evaluating minmax_global...\n",
      "Success\n",
      "    Evaluating minmax_pixel...\n",
      "Success\n",
      "    Evaluating zscore_global...\n",
      "Success\n",
      "    Evaluating zscore_pixel...\n",
      "Success\n",
      "    Evaluating instance_zscore...\n",
      "Success\n",
      "    Evaluating instance_minmax...\n",
      "Success\n",
      "\n",
      "SSP126 Scenario\n",
      "----------------------------------------\n",
      "    Evaluating none...\n",
      "Success\n",
      "    Evaluating minmax_global...\n",
      "Success\n",
      "    Evaluating minmax_pixel...\n",
      "Success\n",
      "    Evaluating zscore_global...\n",
      "Success\n",
      "    Evaluating zscore_pixel...\n",
      "Success\n",
      "    Evaluating instance_zscore...\n",
      "Success\n",
      "    Evaluating instance_minmax...\n",
      "Success\n",
      "\n",
      "SSP245 Scenario\n",
      "----------------------------------------\n",
      "    Evaluating none...\n",
      "Success\n",
      "    Evaluating minmax_global...\n",
      "Success\n",
      "    Evaluating minmax_pixel...\n",
      "Success\n",
      "    Evaluating zscore_global...\n",
      "Success\n",
      "    Evaluating zscore_pixel...\n",
      "Success\n",
      "    Evaluating instance_zscore...\n",
      "Success\n",
      "    Evaluating instance_minmax...\n",
      "Success\n",
      "\n",
      "SSP585 Scenario\n",
      "----------------------------------------\n",
      "    Evaluating none...\n",
      "Success\n",
      "    Evaluating minmax_global...\n",
      "Success\n",
      "    Evaluating minmax_pixel...\n",
      "Success\n",
      "    Evaluating zscore_global...\n",
      "Success\n",
      "    Evaluating zscore_pixel...\n",
      "Success\n",
      "    Evaluating instance_zscore...\n",
      "Success\n",
      "    Evaluating instance_minmax...\n",
      "Success\n",
      "\n",
      "================================================================================\n",
      "SAVING RESULTS\n",
      "================================================================================\n",
      " Saved: evaluation_results/hurs_evaluation_historical.nc\n",
      " Saved: evaluation_results/hurs_evaluation_ssp126.nc\n",
      " Saved: evaluation_results/hurs_evaluation_ssp245.nc\n",
      " Saved: evaluation_results/hurs_evaluation_ssp585.nc\n"
     ]
    }
   ],
   "source": [
    "# evaluate_hurs.py\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from unet import UNet\n",
    "\n",
    "# ----------------------------\n",
    "# Configuration\n",
    "# ----------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_dir = Path(\"data\")\n",
    "ckpt_dir = Path(\"ckpts\")\n",
    "\n",
    "# Variable configuration\n",
    "variable = 'hurs_hr'\n",
    "var_base = 'hurs'\n",
    "var_lr = 'hurs_lr_interp'\n",
    "\n",
    "# Models to evaluate\n",
    "normalizations = ['none', 'minmax_global', 'minmax_pixel', 'zscore_global', \n",
    "                 'zscore_pixel', 'instance_zscore', 'instance_minmax']\n",
    "\n",
    "# Test periods\n",
    "test_periods = {\n",
    "    'historical': ('2001', '2014'),\n",
    "    'ssp126': ('2015', '2100'),\n",
    "    'ssp245': ('2015', '2100'), \n",
    "    'ssp585': ('2015', '2100')\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# Load data \n",
    "# ----------------------------\n",
    "print(\"Loading datasets...\")\n",
    "ds_hist = xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_historical_r1i1p1f1_1850_2014_allvars.nc\")\n",
    "ds_ssp126 = xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_ssp126_r1i1p1f1_2015_2100_allvars.nc\")\n",
    "ds_ssp245 = xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_ssp245_r1i1p1f1_2015_2100_allvars.nc\")\n",
    "ds_ssp585 = xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_ssp585_r1i1p1f1_2015_2100_allvars.nc\")\n",
    "\n",
    "datasets = {\n",
    "    'historical': ds_hist,\n",
    "    'ssp126': ds_ssp126,\n",
    "    'ssp245': ds_ssp245,\n",
    "    'ssp585': ds_ssp585\n",
    "}\n",
    "\n",
    "# Load normalization statistics\n",
    "print(\"Loading normalization statistics...\")\n",
    "with open(data_dir / \"norm_stats.pkl\", 'rb') as f:\n",
    "    norm_stats = pickle.load(f)\n",
    "\n",
    "print(\"Normalization stats loaded for variables:\", list(norm_stats.keys()))\n",
    "\n",
    "# ----------------------------\n",
    "# Normalization helpers \n",
    "# ----------------------------\n",
    "def apply_normalization(data, method, norm_stats, var_base, resolution='lr_interp'):\n",
    "    \"\"\"Apply normalization method to data.\"\"\"\n",
    "    if method == 'none':\n",
    "        return data\n",
    "    \n",
    "    elif method == 'minmax_global':\n",
    "        data_min = norm_stats[var_base][resolution]['global_min']\n",
    "        data_max = norm_stats[var_base][resolution]['global_max']\n",
    "        return 2 * (data - data_min) / (data_max - data_min + 1e-8) - 1\n",
    "    \n",
    "    elif method == 'minmax_pixel':\n",
    "        # CHANGED: pixel stats are already numpy arrays\n",
    "        data_min = norm_stats[var_base][resolution]['pixel_min']\n",
    "        data_max = norm_stats[var_base][resolution]['pixel_max']\n",
    "        return 2 * (data - data_min) / (data_max - data_min + 1e-8) - 1\n",
    "    \n",
    "    elif method == 'zscore_global':\n",
    "        data_mean = norm_stats[var_base][resolution]['global_mean']\n",
    "        data_std = norm_stats[var_base][resolution]['global_std']\n",
    "        return (data - data_mean) / (data_std + 1e-8)\n",
    "    \n",
    "    elif method == 'zscore_pixel':\n",
    "        # CHANGED: pixel stats are already numpy arrays\n",
    "        data_mean = norm_stats[var_base][resolution]['pixel_mean']\n",
    "        data_std = norm_stats[var_base][resolution]['pixel_std']\n",
    "        return (data - data_mean) / (data_std + 1e-8)\n",
    "    \n",
    "    elif method == 'instance_zscore':\n",
    "        # Per-sample normalization - convert to numpy immediately\n",
    "        data_np = data.values if hasattr(data, 'values') else data\n",
    "        data_mean = np.mean(data_np, axis=(1, 2), keepdims=True)\n",
    "        data_std = np.std(data_np, axis=(1, 2), keepdims=True)\n",
    "        data_normalized = (data_np - data_mean) / (data_std + 1e-8)\n",
    "        return data_normalized  # Return numpy array\n",
    "    \n",
    "    elif method == 'instance_minmax':\n",
    "        # Per-sample min-max to [-1, 1] - convert to numpy immediately\n",
    "        data_np = data.values if hasattr(data, 'values') else data\n",
    "        data_min = np.min(data_np, axis=(1, 2), keepdims=True)\n",
    "        data_max = np.max(data_np, axis=(1, 2), keepdims=True)\n",
    "        data_normalized = 2 * (data_np - data_min) / (data_max - data_min + 1e-8) - 1\n",
    "        return data_normalized  # Return numpy array\n",
    "\n",
    "def denormalize_predictions(predictions, method, norm_stats, var_base, input_data=None):\n",
    "    \"\"\"Denormalize predictions back to original scale.\"\"\"\n",
    "    if method == 'none':\n",
    "        return predictions\n",
    "    \n",
    "    elif method == 'minmax_global':\n",
    "        hr_min = norm_stats[var_base]['hr']['global_min']\n",
    "        hr_max = norm_stats[var_base]['hr']['global_max']\n",
    "        return ((predictions + 1) / 2) * (hr_max - hr_min) + hr_min\n",
    "    \n",
    "    elif method == 'minmax_pixel':\n",
    "        hr_min = norm_stats[var_base]['hr']['pixel_min']\n",
    "        hr_max = norm_stats[var_base]['hr']['pixel_max']\n",
    "        return ((predictions + 1) / 2) * (hr_max - hr_min) + hr_min\n",
    "    \n",
    "    elif method == 'zscore_global':\n",
    "        hr_mean = norm_stats[var_base]['hr']['global_mean']\n",
    "        hr_std = norm_stats[var_base]['hr']['global_std']\n",
    "        return predictions * hr_std + hr_mean\n",
    "    \n",
    "    elif method == 'zscore_pixel':\n",
    "        hr_mean = norm_stats[var_base]['hr']['pixel_mean']\n",
    "        hr_std = norm_stats[var_base]['hr']['pixel_std']\n",
    "        return predictions * hr_std + hr_mean\n",
    "    \n",
    "    elif method == 'instance_zscore':\n",
    "        # Need input statistics for denormalization\n",
    "        input_mean = np.mean(input_data, axis=(1, 2), keepdims=True)\n",
    "        input_std = np.std(input_data, axis=(1, 2), keepdims=True)\n",
    "        return predictions * input_std + input_mean\n",
    "    \n",
    "    elif method == 'instance_minmax':\n",
    "        # Need input statistics for denormalization\n",
    "        input_min = np.min(input_data, axis=(1, 2), keepdims=True)\n",
    "        input_max = np.max(input_data, axis=(1, 2), keepdims=True)\n",
    "        return ((predictions + 1) / 2) * (input_max - input_min) + input_min\n",
    "\n",
    "# ----------------------------\n",
    "# Model evaluation\n",
    "# ----------------------------\n",
    "def evaluate_model(model_path, norm_method, dataset, test_period):\n",
    "    \"\"\"Evaluate a single model on a dataset.\"\"\"\n",
    "    print(f\"    Evaluating {norm_method}...\")\n",
    "    \n",
    "    # Load model\n",
    "    model = UNet(in_channels=1, out_channels=1, initial_features=32, depth=5, dropout=0.2)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Extract test data - CONVERT TO NUMPY IMMEDIATELY\n",
    "    lr_data_xr = dataset[var_lr].sel(time=slice(test_period[0], test_period[1]))\n",
    "    hr_data_xr = dataset[variable].sel(time=slice(test_period[0], test_period[1]))\n",
    "    \n",
    "    lr_data_raw = lr_data_xr.values\n",
    "    hr_data_raw = hr_data_xr.values\n",
    "    \n",
    "    # Apply normalization to input (works with numpy or xarray)\n",
    "    lr_data_norm = apply_normalization(lr_data_xr, norm_method, norm_stats, var_base)\n",
    "    \n",
    "    # Ensure it's numpy\n",
    "    if hasattr(lr_data_norm, 'values'):\n",
    "        lr_data_norm = lr_data_norm.values\n",
    "    \n",
    "    # Predict in batches\n",
    "    batch_size = 32\n",
    "    n_samples = len(lr_data_norm)\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, n_samples, batch_size):\n",
    "            batch = lr_data_norm[i:i+batch_size]\n",
    "            batch_tensor = torch.tensor(batch, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "            \n",
    "            # Get predictions\n",
    "            batch_pred = model(batch_tensor)\n",
    "            predictions.append(batch_pred.cpu().numpy())\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0).squeeze(1)\n",
    "    \n",
    "    # Denormalize predictions\n",
    "    predictions_denorm = denormalize_predictions(\n",
    "        predictions, norm_method, norm_stats, var_base, lr_data_raw\n",
    "    )\n",
    "    \n",
    "    return predictions_denorm, hr_data_raw, lr_data_raw\n",
    "\n",
    "# ----------------------------\n",
    "# Main evaluation loop\n",
    "# ----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUATING RELATIVE HUMIDITY (HURS) MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Store all results\n",
    "all_results = {}\n",
    "\n",
    "for scenario_name, dataset in datasets.items():\n",
    "    print(f\"\\n{scenario_name.upper()} Scenario\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    test_period = test_periods[scenario_name]\n",
    "    scenario_results = {}\n",
    "    \n",
    "    # Get ground truth (same for all models)\n",
    "    hr_data = dataset[variable].sel(time=slice(test_period[0], test_period[1]))\n",
    "    lr_data = dataset[var_lr].sel(time=slice(test_period[0], test_period[1]))\n",
    "    time_coords = hr_data.time\n",
    "    lat_coords = hr_data.lat\n",
    "    lon_coords = hr_data.lon\n",
    "    \n",
    "    # Store ground truth and input\n",
    "    scenario_results['groundtruth'] = hr_data\n",
    "    scenario_results['input'] = lr_data\n",
    "    \n",
    "    # Evaluate each model\n",
    "    for norm_method in normalizations:\n",
    "        model_path = ckpt_dir / f\"hurs_{norm_method}.pth\"\n",
    "        \n",
    "        if not model_path.exists():\n",
    "            print(f\"Model not found: {model_path}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            predictions, groundtruth, inputs = evaluate_model(\n",
    "                model_path, norm_method, dataset, test_period\n",
    "            )\n",
    "            \n",
    "            # Create xarray DataArray for predictions\n",
    "            pred_da = xr.DataArray(\n",
    "                predictions,\n",
    "                coords={'time': time_coords, 'lat': lat_coords, 'lon': lon_coords},\n",
    "                dims=['time', 'lat', 'lon'],\n",
    "                name=f'hurs_pred_{norm_method}'\n",
    "            )\n",
    "            \n",
    "            scenario_results[f'pred_{norm_method}'] = pred_da\n",
    "            print(f\"Success\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    all_results[scenario_name] = scenario_results\n",
    "\n",
    "# ----------------------------\n",
    "# Save results\n",
    "# ----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "output_dir = Path(\"evaluation_results\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for scenario_name, results in all_results.items():\n",
    "    # Create dataset with all predictions\n",
    "    ds_result = xr.Dataset()\n",
    "    \n",
    "    # Add ground truth and input\n",
    "    ds_result['groundtruth'] = results['groundtruth']\n",
    "    ds_result['input'] = results['input']\n",
    "    \n",
    "    # Add all predictions\n",
    "    for norm_method in normalizations:\n",
    "        key = f'pred_{norm_method}'\n",
    "        if key in results:\n",
    "            ds_result[key] = results[key]\n",
    "    \n",
    "    # Save to NetCDF\n",
    "    output_path = output_dir / f\"hurs_evaluation_{scenario_name}.nc\"\n",
    "    ds_result.to_netcdf(output_path)\n",
    "    print(f\" Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a0ed72-bd53-4a4b-b9b0-c82887caea15",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38838a68-fa35-43fd-b233-da05b18e5b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Loading normalization statistics...\n",
      "Normalization stats loaded for variables: ['pr', 'tas', 'hurs', 'sfcWind']\n",
      "\n",
      "================================================================================\n",
      "EVALUATING TEMPERATURE (TAS) MODELS\n",
      "================================================================================\n",
      "\n",
      "HISTORICAL Scenario\n",
      "----------------------------------------\n",
      "    Evaluating none...\n",
      "Success\n",
      "    Evaluating minmax_global...\n",
      "Success\n",
      "    Evaluating minmax_pixel...\n",
      "Success\n",
      "    Evaluating zscore_global...\n",
      "Success\n",
      "    Evaluating zscore_pixel...\n",
      "Success\n",
      "    Evaluating instance_zscore...\n",
      "Success\n",
      "    Evaluating instance_minmax...\n",
      "Success\n",
      "\n",
      "SSP126 Scenario\n",
      "----------------------------------------\n",
      "    Evaluating none...\n",
      "Success\n",
      "    Evaluating minmax_global...\n",
      "Success\n",
      "    Evaluating minmax_pixel...\n",
      "Success\n",
      "    Evaluating zscore_global...\n",
      "Success\n",
      "    Evaluating zscore_pixel...\n",
      "Success\n",
      "    Evaluating instance_zscore...\n",
      "Success\n",
      "    Evaluating instance_minmax...\n",
      "Success\n",
      "\n",
      "SSP245 Scenario\n",
      "----------------------------------------\n",
      "    Evaluating none...\n",
      "Success\n",
      "    Evaluating minmax_global...\n",
      "Success\n",
      "    Evaluating minmax_pixel...\n",
      "Success\n",
      "    Evaluating zscore_global...\n",
      "Success\n",
      "    Evaluating zscore_pixel...\n",
      "Success\n",
      "    Evaluating instance_zscore...\n",
      "Success\n",
      "    Evaluating instance_minmax...\n",
      "Success\n",
      "\n",
      "SSP585 Scenario\n",
      "----------------------------------------\n",
      "    Evaluating none...\n",
      "Success\n",
      "    Evaluating minmax_global...\n",
      "Success\n",
      "    Evaluating minmax_pixel...\n",
      "Success\n",
      "    Evaluating zscore_global...\n",
      "Success\n",
      "    Evaluating zscore_pixel...\n",
      "Success\n",
      "    Evaluating instance_zscore...\n",
      "Success\n",
      "    Evaluating instance_minmax...\n",
      "Success\n",
      "\n",
      "================================================================================\n",
      "SAVING RESULTS\n",
      "================================================================================\n",
      "Saved: evaluation_results/tas_evaluation_historical.nc\n",
      "Saved: evaluation_results/tas_evaluation_ssp126.nc\n",
      "Saved: evaluation_results/tas_evaluation_ssp245.nc\n",
      "Saved: evaluation_results/tas_evaluation_ssp585.nc\n",
      "\n",
      "Evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "# evaluate_tas.py\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from unet import UNet\n",
    "\n",
    "# ----------------------------\n",
    "# Configuration\n",
    "# ----------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_dir = Path(\"data\")\n",
    "ckpt_dir = Path(\"ckpts\")\n",
    "\n",
    "# Variable configuration\n",
    "variable = 'tas_hr'\n",
    "var_base = 'tas'\n",
    "var_lr = 'tas_lr_interp'\n",
    "\n",
    "# Models to evaluate\n",
    "normalizations = ['none', 'minmax_global', 'minmax_pixel', 'zscore_global', \n",
    "                 'zscore_pixel', 'instance_zscore', 'instance_minmax']\n",
    "\n",
    "# Test periods\n",
    "test_periods = {\n",
    "    'historical': ('2001', '2014'),\n",
    "    'ssp126': ('2015', '2100'),\n",
    "    'ssp245': ('2015', '2100'), \n",
    "    'ssp585': ('2015', '2100')\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# Load data \n",
    "# ----------------------------\n",
    "print(\"Loading datasets...\")\n",
    "ds_hist = xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_historical_r1i1p1f1_1850_2014_allvars.nc\")\n",
    "ds_ssp126 = xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_ssp126_r1i1p1f1_2015_2100_allvars.nc\")\n",
    "ds_ssp245 = xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_ssp245_r1i1p1f1_2015_2100_allvars.nc\")\n",
    "ds_ssp585 = xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_ssp585_r1i1p1f1_2015_2100_allvars.nc\")\n",
    "\n",
    "datasets = {\n",
    "    'historical': ds_hist,\n",
    "    'ssp126': ds_ssp126,\n",
    "    'ssp245': ds_ssp245,\n",
    "    'ssp585': ds_ssp585\n",
    "}\n",
    "\n",
    "# Load normalization statistics\n",
    "print(\"Loading normalization statistics...\")\n",
    "with open(data_dir / \"norm_stats.pkl\", 'rb') as f:\n",
    "    norm_stats = pickle.load(f)\n",
    "\n",
    "print(\"Normalization stats loaded for variables:\", list(norm_stats.keys()))\n",
    "\n",
    "# ----------------------------\n",
    "# Normalization helpers \n",
    "# ----------------------------\n",
    "def apply_normalization(data, method, norm_stats, var_base, resolution='lr_interp'):\n",
    "    \"\"\"Apply normalization method to data.\"\"\"\n",
    "    if method == 'none':\n",
    "        return data\n",
    "    \n",
    "    elif method == 'minmax_global':\n",
    "        data_min = norm_stats[var_base][resolution]['global_min']\n",
    "        data_max = norm_stats[var_base][resolution]['global_max']\n",
    "        return 2 * (data - data_min) / (data_max - data_min + 1e-8) - 1\n",
    "    \n",
    "    elif method == 'minmax_pixel':\n",
    "        data_min = norm_stats[var_base][resolution]['pixel_min']\n",
    "        data_max = norm_stats[var_base][resolution]['pixel_max']\n",
    "        return 2 * (data - data_min) / (data_max - data_min + 1e-8) - 1\n",
    "    \n",
    "    elif method == 'zscore_global':\n",
    "        data_mean = norm_stats[var_base][resolution]['global_mean']\n",
    "        data_std = norm_stats[var_base][resolution]['global_std']\n",
    "        return (data - data_mean) / (data_std + 1e-8)\n",
    "    \n",
    "    elif method == 'zscore_pixel':\n",
    "        data_mean = norm_stats[var_base][resolution]['pixel_mean']\n",
    "        data_std = norm_stats[var_base][resolution]['pixel_std']\n",
    "        return (data - data_mean) / (data_std + 1e-8)\n",
    "    \n",
    "    elif method == 'instance_zscore':\n",
    "        data_np = data.values if hasattr(data, 'values') else data\n",
    "        data_mean = np.mean(data_np, axis=(1, 2), keepdims=True)\n",
    "        data_std = np.std(data_np, axis=(1, 2), keepdims=True)\n",
    "        data_normalized = (data_np - data_mean) / (data_std + 1e-8)\n",
    "        return data_normalized\n",
    "    \n",
    "    elif method == 'instance_minmax':\n",
    "        data_np = data.values if hasattr(data, 'values') else data\n",
    "        data_min = np.min(data_np, axis=(1, 2), keepdims=True)\n",
    "        data_max = np.max(data_np, axis=(1, 2), keepdims=True)\n",
    "        data_normalized = 2 * (data_np - data_min) / (data_max - data_min + 1e-8) - 1\n",
    "        return data_normalized\n",
    "\n",
    "def denormalize_predictions(predictions, method, norm_stats, var_base, input_data=None):\n",
    "    \"\"\"Denormalize predictions back to original scale.\"\"\"\n",
    "    if method == 'none':\n",
    "        return predictions\n",
    "    \n",
    "    elif method == 'minmax_global':\n",
    "        hr_min = norm_stats[var_base]['hr']['global_min']\n",
    "        hr_max = norm_stats[var_base]['hr']['global_max']\n",
    "        return ((predictions + 1) / 2) * (hr_max - hr_min) + hr_min\n",
    "    \n",
    "    elif method == 'minmax_pixel':\n",
    "        hr_min = norm_stats[var_base]['hr']['pixel_min']\n",
    "        hr_max = norm_stats[var_base]['hr']['pixel_max']\n",
    "        return ((predictions + 1) / 2) * (hr_max - hr_min) + hr_min\n",
    "    \n",
    "    elif method == 'zscore_global':\n",
    "        hr_mean = norm_stats[var_base]['hr']['global_mean']\n",
    "        hr_std = norm_stats[var_base]['hr']['global_std']\n",
    "        return predictions * hr_std + hr_mean\n",
    "    \n",
    "    elif method == 'zscore_pixel':\n",
    "        hr_mean = norm_stats[var_base]['hr']['pixel_mean']\n",
    "        hr_std = norm_stats[var_base]['hr']['pixel_std']\n",
    "        return predictions * hr_std + hr_mean\n",
    "    \n",
    "    elif method == 'instance_zscore':\n",
    "        input_mean = np.mean(input_data, axis=(1, 2), keepdims=True)\n",
    "        input_std = np.std(input_data, axis=(1, 2), keepdims=True)\n",
    "        return predictions * input_std + input_mean\n",
    "    \n",
    "    elif method == 'instance_minmax':\n",
    "        input_min = np.min(input_data, axis=(1, 2), keepdims=True)\n",
    "        input_max = np.max(input_data, axis=(1, 2), keepdims=True)\n",
    "        return ((predictions + 1) / 2) * (input_max - input_min) + input_min\n",
    "\n",
    "# ----------------------------\n",
    "# Model evaluation\n",
    "# ----------------------------\n",
    "def evaluate_model(model_path, norm_method, dataset, test_period):\n",
    "    \"\"\"Evaluate a single model on a dataset.\"\"\"\n",
    "    print(f\"    Evaluating {norm_method}...\")\n",
    "    \n",
    "    # Load model\n",
    "    model = UNet(in_channels=1, out_channels=1, initial_features=32, depth=5, dropout=0.2)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Extract test data\n",
    "    lr_data_xr = dataset[var_lr].sel(time=slice(test_period[0], test_period[1]))\n",
    "    hr_data_xr = dataset[variable].sel(time=slice(test_period[0], test_period[1]))\n",
    "    \n",
    "    lr_data_raw = lr_data_xr.values\n",
    "    hr_data_raw = hr_data_xr.values\n",
    "    \n",
    "    # Apply normalization to input\n",
    "    lr_data_norm = apply_normalization(lr_data_xr, norm_method, norm_stats, var_base)\n",
    "    \n",
    "    # Ensure it's numpy\n",
    "    if hasattr(lr_data_norm, 'values'):\n",
    "        lr_data_norm = lr_data_norm.values\n",
    "    \n",
    "    # Predict in batches\n",
    "    batch_size = 32\n",
    "    n_samples = len(lr_data_norm)\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, n_samples, batch_size):\n",
    "            batch = lr_data_norm[i:i+batch_size]\n",
    "            batch_tensor = torch.tensor(batch, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "            \n",
    "            batch_pred = model(batch_tensor)\n",
    "            predictions.append(batch_pred.cpu().numpy())\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0).squeeze(1)\n",
    "    \n",
    "    # Denormalize predictions\n",
    "    predictions_denorm = denormalize_predictions(\n",
    "        predictions, norm_method, norm_stats, var_base, lr_data_raw\n",
    "    )\n",
    "    \n",
    "    return predictions_denorm, hr_data_raw, lr_data_raw\n",
    "\n",
    "# ----------------------------\n",
    "# Main evaluation loop\n",
    "# ----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUATING TEMPERATURE (TAS) MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for scenario_name, dataset in datasets.items():\n",
    "    print(f\"\\n{scenario_name.upper()} Scenario\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    test_period = test_periods[scenario_name]\n",
    "    scenario_results = {}\n",
    "    \n",
    "    # Get ground truth\n",
    "    hr_data = dataset[variable].sel(time=slice(test_period[0], test_period[1]))\n",
    "    lr_data = dataset[var_lr].sel(time=slice(test_period[0], test_period[1]))\n",
    "    time_coords = hr_data.time\n",
    "    lat_coords = hr_data.lat\n",
    "    lon_coords = hr_data.lon\n",
    "    \n",
    "    # Store ground truth and input\n",
    "    scenario_results['groundtruth'] = hr_data\n",
    "    scenario_results['input'] = lr_data\n",
    "    \n",
    "    # Evaluate each model\n",
    "    for norm_method in normalizations:\n",
    "        model_path = ckpt_dir / f\"tas_{norm_method}.pth\"\n",
    "        \n",
    "        if not model_path.exists():\n",
    "            print(f\"Model not found: {model_path}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            predictions, groundtruth, inputs = evaluate_model(\n",
    "                model_path, norm_method, dataset, test_period\n",
    "            )\n",
    "            \n",
    "            pred_da = xr.DataArray(\n",
    "                predictions,\n",
    "                coords={'time': time_coords, 'lat': lat_coords, 'lon': lon_coords},\n",
    "                dims=['time', 'lat', 'lon'],\n",
    "                name=f'tas_pred_{norm_method}'\n",
    "            )\n",
    "            \n",
    "            scenario_results[f'pred_{norm_method}'] = pred_da\n",
    "            print(f\"Success\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    all_results[scenario_name] = scenario_results\n",
    "\n",
    "# ----------------------------\n",
    "# Save results\n",
    "# ----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "output_dir = Path(\"evaluation_results\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for scenario_name, results in all_results.items():\n",
    "    ds_result = xr.Dataset()\n",
    "    \n",
    "    ds_result['groundtruth'] = results['groundtruth']\n",
    "    ds_result['input'] = results['input']\n",
    "    \n",
    "    for norm_method in normalizations:\n",
    "        key = f'pred_{norm_method}'\n",
    "        if key in results:\n",
    "            ds_result[key] = results[key]\n",
    "    \n",
    "    output_path = output_dir / f\"tas_evaluation_{scenario_name}.nc\"\n",
    "    ds_result.to_netcdf(output_path)\n",
    "    print(f\"Saved: {output_path}\")\n",
    "\n",
    "print(\"\\nEvaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8770c7b-e322-4fa1-9532-dce5de6d8206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home.ufs/yw4236/.local/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home.ufs/yw4236/.local/lib/python3.9/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading G6sulfur dataset...\n",
      "Loading normalization statistics...\n",
      "\n",
      "================================================================================\n",
      "EVALUATING G6SULFUR TEMPERATURE (TAS) MODELS\n",
      "================================================================================\n",
      "    Evaluating none...\n",
      "    none: Success\n",
      "    Evaluating minmax_global...\n",
      "    minmax_global: Success\n",
      "    Evaluating minmax_pixel...\n",
      "    minmax_pixel: Success\n",
      "    Evaluating zscore_global...\n",
      "    zscore_global: Success\n",
      "    Evaluating zscore_pixel...\n",
      "    zscore_pixel: Success\n",
      "    Evaluating instance_zscore...\n",
      "    instance_zscore: Success\n",
      "    Evaluating instance_minmax...\n",
      "    instance_minmax: Success\n",
      "\n",
      "================================================================================\n",
      "SAVING G6SULFUR RESULTS\n",
      "================================================================================\n",
      "   Saved: evaluation_results/tas_evaluation_g6sulfur.nc\n",
      "   Variables: ['groundtruth', 'input', 'pred_none', 'pred_minmax_global', 'pred_minmax_pixel', 'pred_zscore_global', 'pred_zscore_pixel', 'pred_instance_zscore', 'pred_instance_minmax']\n",
      "   Time range: 2020 to 2099\n",
      "\n",
      "G6sulfur evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from unet import UNet\n",
    "\n",
    "# ----------------------------\n",
    "# Configuration\n",
    "# ----------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_dir = Path(\"data\")\n",
    "ckpt_dir = Path(\"ckpts\")\n",
    "\n",
    "# Variable configuration\n",
    "variable = 'tas_hr'\n",
    "var_base = 'tas'\n",
    "var_lr = 'tas_lr_interp'\n",
    "\n",
    "# Models to evaluate\n",
    "normalizations = ['none', 'minmax_global', 'minmax_pixel', 'zscore_global', \n",
    "                 'zscore_pixel', 'instance_zscore', 'instance_minmax']\n",
    "\n",
    "# Test period for G6sulfur\n",
    "test_period_g6 = ('2020', '2099')\n",
    "\n",
    "# ----------------------------\n",
    "# Load data \n",
    "# ----------------------------\n",
    "print(\"Loading G6sulfur dataset...\")\n",
    "ds_g6sulfur = xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_g6sulfur_r1i1p1f1_2020_2099_allvars.nc\")\n",
    "\n",
    "# Load normalization statistics\n",
    "print(\"Loading normalization statistics...\")\n",
    "with open(data_dir / \"norm_stats.pkl\", 'rb') as f:\n",
    "    norm_stats = pickle.load(f)\n",
    "\n",
    "# ----------------------------\n",
    "# Normalization helpers \n",
    "# ----------------------------\n",
    "def apply_normalization(data, method, norm_stats, var_base, resolution='lr_interp'):\n",
    "    \"\"\"Apply normalization method to data.\"\"\"\n",
    "    if method == 'none':\n",
    "        return data\n",
    "    \n",
    "    elif method == 'minmax_global':\n",
    "        data_min = norm_stats[var_base][resolution]['global_min']\n",
    "        data_max = norm_stats[var_base][resolution]['global_max']\n",
    "        return 2 * (data - data_min) / (data_max - data_min + 1e-8) - 1\n",
    "    \n",
    "    elif method == 'minmax_pixel':\n",
    "        data_min = norm_stats[var_base][resolution]['pixel_min']\n",
    "        data_max = norm_stats[var_base][resolution]['pixel_max']\n",
    "        return 2 * (data - data_min) / (data_max - data_min + 1e-8) - 1\n",
    "    \n",
    "    elif method == 'zscore_global':\n",
    "        data_mean = norm_stats[var_base][resolution]['global_mean']\n",
    "        data_std = norm_stats[var_base][resolution]['global_std']\n",
    "        return (data - data_mean) / (data_std + 1e-8)\n",
    "    \n",
    "    elif method == 'zscore_pixel':\n",
    "        data_mean = norm_stats[var_base][resolution]['pixel_mean']\n",
    "        data_std = norm_stats[var_base][resolution]['pixel_std']\n",
    "        return (data - data_mean) / (data_std + 1e-8)\n",
    "    \n",
    "    elif method == 'instance_zscore':\n",
    "        data_np = data.values if hasattr(data, 'values') else data\n",
    "        data_mean = np.mean(data_np, axis=(1, 2), keepdims=True)\n",
    "        data_std = np.std(data_np, axis=(1, 2), keepdims=True)\n",
    "        data_normalized = (data_np - data_mean) / (data_std + 1e-8)\n",
    "        return data_normalized\n",
    "    \n",
    "    elif method == 'instance_minmax':\n",
    "        data_np = data.values if hasattr(data, 'values') else data\n",
    "        data_min = np.min(data_np, axis=(1, 2), keepdims=True)\n",
    "        data_max = np.max(data_np, axis=(1, 2), keepdims=True)\n",
    "        data_normalized = 2 * (data_np - data_min) / (data_max - data_min + 1e-8) - 1\n",
    "        return data_normalized\n",
    "\n",
    "def denormalize_predictions(predictions, method, norm_stats, var_base, input_data=None):\n",
    "    \"\"\"Denormalize predictions back to original scale.\"\"\"\n",
    "    if method == 'none':\n",
    "        return predictions\n",
    "    \n",
    "    elif method == 'minmax_global':\n",
    "        hr_min = norm_stats[var_base]['hr']['global_min']\n",
    "        hr_max = norm_stats[var_base]['hr']['global_max']\n",
    "        return ((predictions + 1) / 2) * (hr_max - hr_min) + hr_min\n",
    "    \n",
    "    elif method == 'minmax_pixel':\n",
    "        hr_min = norm_stats[var_base]['hr']['pixel_min']\n",
    "        hr_max = norm_stats[var_base]['hr']['pixel_max']\n",
    "        return ((predictions + 1) / 2) * (hr_max - hr_min) + hr_min\n",
    "    \n",
    "    elif method == 'zscore_global':\n",
    "        hr_mean = norm_stats[var_base]['hr']['global_mean']\n",
    "        hr_std = norm_stats[var_base]['hr']['global_std']\n",
    "        return predictions * hr_std + hr_mean\n",
    "    \n",
    "    elif method == 'zscore_pixel':\n",
    "        hr_mean = norm_stats[var_base]['hr']['pixel_mean']\n",
    "        hr_std = norm_stats[var_base]['hr']['pixel_std']\n",
    "        return predictions * hr_std + hr_mean\n",
    "    \n",
    "    elif method == 'instance_zscore':\n",
    "        input_mean = np.mean(input_data, axis=(1, 2), keepdims=True)\n",
    "        input_std = np.std(input_data, axis=(1, 2), keepdims=True)\n",
    "        return predictions * input_std + input_mean\n",
    "    \n",
    "    elif method == 'instance_minmax':\n",
    "        input_min = np.min(input_data, axis=(1, 2), keepdims=True)\n",
    "        input_max = np.max(input_data, axis=(1, 2), keepdims=True)\n",
    "        return ((predictions + 1) / 2) * (input_max - input_min) + input_min\n",
    "\n",
    "# ----------------------------\n",
    "# Model evaluation\n",
    "# ----------------------------\n",
    "def evaluate_model(model_path, norm_method, dataset, test_period):\n",
    "    \"\"\"Evaluate a single model on a dataset.\"\"\"\n",
    "    print(f\"    Evaluating {norm_method}...\")\n",
    "    \n",
    "    # Load model\n",
    "    model = UNet(in_channels=1, out_channels=1, initial_features=32, depth=5, dropout=0.2)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Extract test data\n",
    "    lr_data_xr = dataset[var_lr].sel(time=slice(test_period[0], test_period[1]))\n",
    "    hr_data_xr = dataset[variable].sel(time=slice(test_period[0], test_period[1]))\n",
    "    \n",
    "    lr_data_raw = lr_data_xr.values\n",
    "    hr_data_raw = hr_data_xr.values\n",
    "    \n",
    "    # Apply normalization to input\n",
    "    lr_data_norm = apply_normalization(lr_data_xr, norm_method, norm_stats, var_base)\n",
    "    \n",
    "    # Ensure it's numpy\n",
    "    if hasattr(lr_data_norm, 'values'):\n",
    "        lr_data_norm = lr_data_norm.values\n",
    "    \n",
    "    # Predict in batches\n",
    "    batch_size = 32\n",
    "    n_samples = len(lr_data_norm)\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, n_samples, batch_size):\n",
    "            batch = lr_data_norm[i:i+batch_size]\n",
    "            batch_tensor = torch.tensor(batch, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "            \n",
    "            batch_pred = model(batch_tensor)\n",
    "            predictions.append(batch_pred.cpu().numpy())\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0).squeeze(1)\n",
    "    \n",
    "    # Denormalize predictions\n",
    "    predictions_denorm = denormalize_predictions(\n",
    "        predictions, norm_method, norm_stats, var_base, lr_data_raw\n",
    "    )\n",
    "    \n",
    "    return predictions_denorm, hr_data_raw, lr_data_raw\n",
    "\n",
    "# ----------------------------\n",
    "# Main evaluation for G6sulfur\n",
    "# ----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUATING G6SULFUR TEMPERATURE (TAS) MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "g6_results = {}\n",
    "\n",
    "# Get ground truth\n",
    "hr_data = ds_g6sulfur[variable].sel(time=slice(test_period_g6[0], test_period_g6[1]))\n",
    "lr_data = ds_g6sulfur[var_lr].sel(time=slice(test_period_g6[0], test_period_g6[1]))\n",
    "time_coords = hr_data.time\n",
    "lat_coords = hr_data.lat\n",
    "lon_coords = hr_data.lon\n",
    "\n",
    "# Store ground truth and input\n",
    "g6_results['groundtruth'] = hr_data\n",
    "g6_results['input'] = lr_data\n",
    "\n",
    "# Evaluate each model\n",
    "for norm_method in normalizations:\n",
    "    model_path = ckpt_dir / f\"tas_{norm_method}.pth\"\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        print(f\"Model not found: {model_path}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        predictions, groundtruth, inputs = evaluate_model(\n",
    "            model_path, norm_method, ds_g6sulfur, test_period_g6\n",
    "        )\n",
    "        \n",
    "        pred_da = xr.DataArray(\n",
    "            predictions,\n",
    "            coords={'time': time_coords, 'lat': lat_coords, 'lon': lon_coords},\n",
    "            dims=['time', 'lat', 'lon'],\n",
    "            name=f'tas_pred_{norm_method}'\n",
    "        )\n",
    "        \n",
    "        g6_results[f'pred_{norm_method}'] = pred_da\n",
    "        print(f\"    {norm_method}: Success\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    {norm_method}: Error - {e}\")\n",
    "        continue\n",
    "\n",
    "# ----------------------------\n",
    "# Save results\n",
    "# ----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING G6SULFUR RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "output_dir = Path(\"evaluation_results\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "ds_result = xr.Dataset()\n",
    "ds_result['groundtruth'] = g6_results['groundtruth']\n",
    "ds_result['input'] = g6_results['input']\n",
    "\n",
    "for norm_method in normalizations:\n",
    "    key = f'pred_{norm_method}'\n",
    "    if key in g6_results:\n",
    "        ds_result[key] = g6_results[key]\n",
    "\n",
    "output_path = output_dir / \"tas_evaluation_g6sulfur.nc\"\n",
    "ds_result.to_netcdf(output_path)\n",
    "print(f\"   Saved: {output_path}\")\n",
    "print(f\"   Variables: {list(ds_result.data_vars)}\")\n",
    "print(f\"   Time range: {test_period_g6[0]} to {test_period_g6[1]}\")\n",
    "\n",
    "print(\"\\nG6sulfur evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25ccee7-d361-4a64-98d9-8b7e166f40e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fde7a0e6-4653-4a7c-bfa4-dd61eac99c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Loading normalization statistics...\n",
      "Normalization stats loaded for variables: ['pr', 'tas', 'hurs', 'sfcWind']\n",
      "\n",
      "================================================================================\n",
      "EVALUATING PRECIPITATION (PR) MODELS\n",
      "================================================================================\n",
      "\n",
      "HISTORICAL Scenario\n",
      "----------------------------------------\n",
      "    Evaluating none...\n",
      "Success\n",
      "    Evaluating minmax_global...\n",
      "Success\n",
      "    Evaluating minmax_pixel...\n",
      "Success\n",
      "    Evaluating zscore_global...\n",
      "Success\n",
      "    Evaluating zscore_pixel...\n",
      "Success\n",
      "    Evaluating instance_zscore...\n",
      "Success\n",
      "    Evaluating instance_minmax...\n",
      "Success\n",
      "\n",
      "SSP126 Scenario\n",
      "----------------------------------------\n",
      "    Evaluating none...\n",
      "Success\n",
      "    Evaluating minmax_global...\n",
      "Success\n",
      "    Evaluating minmax_pixel...\n",
      "Success\n",
      "    Evaluating zscore_global...\n",
      "Success\n",
      "    Evaluating zscore_pixel...\n",
      "Success\n",
      "    Evaluating instance_zscore...\n",
      "Success\n",
      "    Evaluating instance_minmax...\n",
      "Success\n",
      "\n",
      "SSP245 Scenario\n",
      "----------------------------------------\n",
      "    Evaluating none...\n",
      "Success\n",
      "    Evaluating minmax_global...\n",
      "Success\n",
      "    Evaluating minmax_pixel...\n",
      "Success\n",
      "    Evaluating zscore_global...\n",
      "Success\n",
      "    Evaluating zscore_pixel...\n",
      "Success\n",
      "    Evaluating instance_zscore...\n",
      "Success\n",
      "    Evaluating instance_minmax...\n",
      "Success\n",
      "\n",
      "SSP585 Scenario\n",
      "----------------------------------------\n",
      "    Evaluating none...\n",
      "Success\n",
      "    Evaluating minmax_global...\n",
      "Success\n",
      "    Evaluating minmax_pixel...\n",
      "Success\n",
      "    Evaluating zscore_global...\n",
      "Success\n",
      "    Evaluating zscore_pixel...\n",
      "Success\n",
      "    Evaluating instance_zscore...\n",
      "Success\n",
      "    Evaluating instance_minmax...\n",
      "Success\n",
      "\n",
      "================================================================================\n",
      "SAVING RESULTS\n",
      "================================================================================\n",
      "Saved: evaluation_results/pr_evaluation_historical.nc\n",
      "Saved: evaluation_results/pr_evaluation_ssp126.nc\n",
      "Saved: evaluation_results/pr_evaluation_ssp245.nc\n",
      "Saved: evaluation_results/pr_evaluation_ssp585.nc\n",
      "\n",
      "Evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "# evaluate_pr.py\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from unet import UNet\n",
    "\n",
    "# ----------------------------\n",
    "# Configuration\n",
    "# ----------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_dir = Path(\"data\")\n",
    "ckpt_dir = Path(\"ckpts\")\n",
    "\n",
    "# Variable configuration\n",
    "variable = 'pr_hr'\n",
    "var_base = 'pr'\n",
    "var_lr = 'pr_lr_interp'\n",
    "\n",
    "# Models to evaluate\n",
    "normalizations = ['none', 'minmax_global', 'minmax_pixel', 'zscore_global', \n",
    "                 'zscore_pixel', 'instance_zscore', 'instance_minmax']\n",
    "\n",
    "# Test periods\n",
    "test_periods = {\n",
    "    'historical': ('2001', '2014'),\n",
    "    'ssp126': ('2015', '2100'),\n",
    "    'ssp245': ('2015', '2100'), \n",
    "    'ssp585': ('2015', '2100')\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# Load data \n",
    "# ----------------------------\n",
    "print(\"Loading datasets...\")\n",
    "ds_hist = xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_historical_r1i1p1f1_1850_2014_allvars.nc\")\n",
    "ds_ssp126 = xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_ssp126_r1i1p1f1_2015_2100_allvars.nc\")\n",
    "ds_ssp245 = xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_ssp245_r1i1p1f1_2015_2100_allvars.nc\")\n",
    "ds_ssp585 = xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_ssp585_r1i1p1f1_2015_2100_allvars.nc\")\n",
    "\n",
    "datasets = {\n",
    "    'historical': ds_hist,\n",
    "    'ssp126': ds_ssp126,\n",
    "    'ssp245': ds_ssp245,\n",
    "    'ssp585': ds_ssp585\n",
    "}\n",
    "\n",
    "# Load normalization statistics\n",
    "print(\"Loading normalization statistics...\")\n",
    "with open(data_dir / \"norm_stats.pkl\", 'rb') as f:\n",
    "    norm_stats = pickle.load(f)\n",
    "\n",
    "print(\"Normalization stats loaded for variables:\", list(norm_stats.keys()))\n",
    "\n",
    "# ----------------------------\n",
    "# Normalization helpers \n",
    "# ----------------------------\n",
    "def apply_normalization(data, method, norm_stats, var_base, resolution='lr_interp'):\n",
    "    \"\"\"Apply normalization method to data.\"\"\"\n",
    "    if method == 'none':\n",
    "        return data\n",
    "    \n",
    "    elif method == 'minmax_global':\n",
    "        data_min = norm_stats[var_base][resolution]['global_min']\n",
    "        data_max = norm_stats[var_base][resolution]['global_max']\n",
    "        return 2 * (data - data_min) / (data_max - data_min + 1e-8) - 1\n",
    "    \n",
    "    elif method == 'minmax_pixel':\n",
    "        data_min = norm_stats[var_base][resolution]['pixel_min']\n",
    "        data_max = norm_stats[var_base][resolution]['pixel_max']\n",
    "        return 2 * (data - data_min) / (data_max - data_min + 1e-8) - 1\n",
    "    \n",
    "    elif method == 'zscore_global':\n",
    "        data_mean = norm_stats[var_base][resolution]['global_mean']\n",
    "        data_std = norm_stats[var_base][resolution]['global_std']\n",
    "        return (data - data_mean) / (data_std + 1e-8)\n",
    "    \n",
    "    elif method == 'zscore_pixel':\n",
    "        data_mean = norm_stats[var_base][resolution]['pixel_mean']\n",
    "        data_std = norm_stats[var_base][resolution]['pixel_std']\n",
    "        return (data - data_mean) / (data_std + 1e-8)\n",
    "    \n",
    "    elif method == 'instance_zscore':\n",
    "        data_np = data.values if hasattr(data, 'values') else data\n",
    "        data_mean = np.mean(data_np, axis=(1, 2), keepdims=True)\n",
    "        data_std = np.std(data_np, axis=(1, 2), keepdims=True)\n",
    "        data_normalized = (data_np - data_mean) / (data_std + 1e-8)\n",
    "        return data_normalized\n",
    "    \n",
    "    elif method == 'instance_minmax':\n",
    "        data_np = data.values if hasattr(data, 'values') else data\n",
    "        data_min = np.min(data_np, axis=(1, 2), keepdims=True)\n",
    "        data_max = np.max(data_np, axis=(1, 2), keepdims=True)\n",
    "        data_normalized = 2 * (data_np - data_min) / (data_max - data_min + 1e-8) - 1\n",
    "        return data_normalized\n",
    "\n",
    "def denormalize_predictions(predictions, method, norm_stats, var_base, input_data=None):\n",
    "    \"\"\"Denormalize predictions back to original scale.\"\"\"\n",
    "    if method == 'none':\n",
    "        return predictions\n",
    "    \n",
    "    elif method == 'minmax_global':\n",
    "        hr_min = norm_stats[var_base]['hr']['global_min']\n",
    "        hr_max = norm_stats[var_base]['hr']['global_max']\n",
    "        return ((predictions + 1) / 2) * (hr_max - hr_min) + hr_min\n",
    "    \n",
    "    elif method == 'minmax_pixel':\n",
    "        hr_min = norm_stats[var_base]['hr']['pixel_min']\n",
    "        hr_max = norm_stats[var_base]['hr']['pixel_max']\n",
    "        return ((predictions + 1) / 2) * (hr_max - hr_min) + hr_min\n",
    "    \n",
    "    elif method == 'zscore_global':\n",
    "        hr_mean = norm_stats[var_base]['hr']['global_mean']\n",
    "        hr_std = norm_stats[var_base]['hr']['global_std']\n",
    "        return predictions * hr_std + hr_mean\n",
    "    \n",
    "    elif method == 'zscore_pixel':\n",
    "        hr_mean = norm_stats[var_base]['hr']['pixel_mean']\n",
    "        hr_std = norm_stats[var_base]['hr']['pixel_std']\n",
    "        return predictions * hr_std + hr_mean\n",
    "    \n",
    "    elif method == 'instance_zscore':\n",
    "        input_mean = np.mean(input_data, axis=(1, 2), keepdims=True)\n",
    "        input_std = np.std(input_data, axis=(1, 2), keepdims=True)\n",
    "        return predictions * input_std + input_mean\n",
    "    \n",
    "    elif method == 'instance_minmax':\n",
    "        input_min = np.min(input_data, axis=(1, 2), keepdims=True)\n",
    "        input_max = np.max(input_data, axis=(1, 2), keepdims=True)\n",
    "        return ((predictions + 1) / 2) * (input_max - input_min) + input_min\n",
    "\n",
    "# ----------------------------\n",
    "# Model evaluation\n",
    "# ----------------------------\n",
    "def evaluate_model(model_path, norm_method, dataset, test_period):\n",
    "    \"\"\"Evaluate a single model on a dataset.\"\"\"\n",
    "    print(f\"    Evaluating {norm_method}...\")\n",
    "    \n",
    "    # Load model\n",
    "    model = UNet(in_channels=1, out_channels=1, initial_features=32, depth=5, dropout=0.2)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Extract test data\n",
    "    lr_data_xr = dataset[var_lr].sel(time=slice(test_period[0], test_period[1]))\n",
    "    hr_data_xr = dataset[variable].sel(time=slice(test_period[0], test_period[1]))\n",
    "    \n",
    "    lr_data_raw = lr_data_xr.values\n",
    "    hr_data_raw = hr_data_xr.values\n",
    "    \n",
    "    # Apply normalization to input\n",
    "    lr_data_norm = apply_normalization(lr_data_xr, norm_method, norm_stats, var_base)\n",
    "    \n",
    "    # Ensure it's numpy\n",
    "    if hasattr(lr_data_norm, 'values'):\n",
    "        lr_data_norm = lr_data_norm.values\n",
    "    \n",
    "    # Predict in batches\n",
    "    batch_size = 32\n",
    "    n_samples = len(lr_data_norm)\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, n_samples, batch_size):\n",
    "            batch = lr_data_norm[i:i+batch_size]\n",
    "            batch_tensor = torch.tensor(batch, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "            \n",
    "            batch_pred = model(batch_tensor)\n",
    "            predictions.append(batch_pred.cpu().numpy())\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0).squeeze(1)\n",
    "    \n",
    "    # Denormalize predictions\n",
    "    predictions_denorm = denormalize_predictions(\n",
    "        predictions, norm_method, norm_stats, var_base, lr_data_raw\n",
    "    )\n",
    "    \n",
    "    return predictions_denorm, hr_data_raw, lr_data_raw\n",
    "\n",
    "# ----------------------------\n",
    "# Main evaluation loop\n",
    "# ----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUATING PRECIPITATION (PR) MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for scenario_name, dataset in datasets.items():\n",
    "    print(f\"\\n{scenario_name.upper()} Scenario\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    test_period = test_periods[scenario_name]\n",
    "    scenario_results = {}\n",
    "    \n",
    "    # Get ground truth\n",
    "    hr_data = dataset[variable].sel(time=slice(test_period[0], test_period[1]))\n",
    "    lr_data = dataset[var_lr].sel(time=slice(test_period[0], test_period[1]))\n",
    "    time_coords = hr_data.time\n",
    "    lat_coords = hr_data.lat\n",
    "    lon_coords = hr_data.lon\n",
    "    \n",
    "    # Store ground truth and input\n",
    "    scenario_results['groundtruth'] = hr_data\n",
    "    scenario_results['input'] = lr_data\n",
    "    \n",
    "    # Evaluate each model\n",
    "    for norm_method in normalizations:\n",
    "        model_path = ckpt_dir / f\"pr_{norm_method}.pth\"\n",
    "        \n",
    "        if not model_path.exists():\n",
    "            print(f\"Model not found: {model_path}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            predictions, groundtruth, inputs = evaluate_model(\n",
    "                model_path, norm_method, dataset, test_period\n",
    "            )\n",
    "            \n",
    "            pred_da = xr.DataArray(\n",
    "                predictions,\n",
    "                coords={'time': time_coords, 'lat': lat_coords, 'lon': lon_coords},\n",
    "                dims=['time', 'lat', 'lon'],\n",
    "                name=f'pr_pred_{norm_method}'\n",
    "            )\n",
    "            \n",
    "            scenario_results[f'pred_{norm_method}'] = pred_da\n",
    "            print(f\"Success\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    all_results[scenario_name] = scenario_results\n",
    "\n",
    "# ----------------------------\n",
    "# Save results\n",
    "# ----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "output_dir = Path(\"evaluation_results\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for scenario_name, results in all_results.items():\n",
    "    ds_result = xr.Dataset()\n",
    "    \n",
    "    ds_result['groundtruth'] = results['groundtruth']\n",
    "    ds_result['input'] = results['input']\n",
    "    \n",
    "    for norm_method in normalizations:\n",
    "        key = f'pred_{norm_method}'\n",
    "        if key in results:\n",
    "            ds_result[key] = results[key]\n",
    "    \n",
    "    output_path = output_dir / f\"pr_evaluation_{scenario_name}.nc\"\n",
    "    ds_result.to_netcdf(output_path)\n",
    "    print(f\"Saved: {output_path}\")\n",
    "\n",
    "print(\"\\nEvaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37734535-6534-4662-ac91-86a2366b8baa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# sfcWind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "691f5cc3-497e-4fb4-9bdf-9de4169cd42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Loading normalization statistics...\n",
      "Normalization stats loaded for variables: ['pr', 'tas', 'hurs', 'sfcWind']\n",
      "\n",
      "================================================================================\n",
      "EVALUATING WIND SPEED (SFCWIND) MODELS\n",
      "================================================================================\n",
      "\n",
      "HISTORICAL Scenario\n",
      "----------------------------------------\n",
      "    Evaluating none...\n",
      "Success\n",
      "    Evaluating minmax_global...\n",
      "Success\n",
      "    Evaluating minmax_pixel...\n",
      "Success\n",
      "    Evaluating zscore_global...\n",
      "Success\n",
      "    Evaluating zscore_pixel...\n",
      "Success\n",
      "    Evaluating instance_zscore...\n",
      "Success\n",
      "    Evaluating instance_minmax...\n",
      "Success\n",
      "\n",
      "SSP126 Scenario\n",
      "----------------------------------------\n",
      "    Evaluating none...\n",
      "Success\n",
      "    Evaluating minmax_global...\n",
      "Success\n",
      "    Evaluating minmax_pixel...\n",
      "Success\n",
      "    Evaluating zscore_global...\n",
      "Success\n",
      "    Evaluating zscore_pixel...\n",
      "Success\n",
      "    Evaluating instance_zscore...\n",
      "Success\n",
      "    Evaluating instance_minmax...\n",
      "Success\n",
      "\n",
      "SSP245 Scenario\n",
      "----------------------------------------\n",
      "    Evaluating none...\n",
      "Success\n",
      "    Evaluating minmax_global...\n",
      "Success\n",
      "    Evaluating minmax_pixel...\n",
      "Success\n",
      "    Evaluating zscore_global...\n",
      "Success\n",
      "    Evaluating zscore_pixel...\n",
      "Success\n",
      "    Evaluating instance_zscore...\n",
      "Success\n",
      "    Evaluating instance_minmax...\n",
      "Success\n",
      "\n",
      "SSP585 Scenario\n",
      "----------------------------------------\n",
      "    Evaluating none...\n",
      "Success\n",
      "    Evaluating minmax_global...\n",
      "Success\n",
      "    Evaluating minmax_pixel...\n",
      "Success\n",
      "    Evaluating zscore_global...\n",
      "Success\n",
      "    Evaluating zscore_pixel...\n",
      "Success\n",
      "    Evaluating instance_zscore...\n",
      "Success\n",
      "    Evaluating instance_minmax...\n",
      "Success\n",
      "\n",
      "================================================================================\n",
      "SAVING RESULTS\n",
      "================================================================================\n",
      "Saved: evaluation_results/sfcWind_evaluation_historical.nc\n",
      "Saved: evaluation_results/sfcWind_evaluation_ssp126.nc\n",
      "Saved: evaluation_results/sfcWind_evaluation_ssp245.nc\n",
      "Saved: evaluation_results/sfcWind_evaluation_ssp585.nc\n",
      "\n",
      "Evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "# evaluate_sfcWind.py\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from unet import UNet\n",
    "\n",
    "# ----------------------------\n",
    "# Configuration\n",
    "# ----------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_dir = Path(\"data\")\n",
    "ckpt_dir = Path(\"ckpts\")\n",
    "\n",
    "# Variable configuration\n",
    "variable = 'sfcWind_hr'\n",
    "var_base = 'sfcWind'\n",
    "var_lr = 'sfcWind_lr_interp'\n",
    "\n",
    "# Models to evaluate\n",
    "normalizations = ['none', 'minmax_global', 'minmax_pixel', 'zscore_global', \n",
    "                 'zscore_pixel', 'instance_zscore', 'instance_minmax']\n",
    "\n",
    "# Test periods\n",
    "test_periods = {\n",
    "    'historical': ('2001', '2014'),\n",
    "    'ssp126': ('2015', '2100'),\n",
    "    'ssp245': ('2015', '2100'), \n",
    "    'ssp585': ('2015', '2100')\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# Load data \n",
    "# ----------------------------\n",
    "print(\"Loading datasets...\")\n",
    "ds_hist = xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_historical_r1i1p1f1_1850_2014_allvars.nc\")\n",
    "ds_ssp126 = xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_ssp126_r1i1p1f1_2015_2100_allvars.nc\")\n",
    "ds_ssp245 = xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_ssp245_r1i1p1f1_2015_2100_allvars.nc\")\n",
    "ds_ssp585 = xr.open_dataset(data_dir / \"MPI-ESM1-2-HR-LR_ssp585_r1i1p1f1_2015_2100_allvars.nc\")\n",
    "\n",
    "datasets = {\n",
    "    'historical': ds_hist,\n",
    "    'ssp126': ds_ssp126,\n",
    "    'ssp245': ds_ssp245,\n",
    "    'ssp585': ds_ssp585\n",
    "}\n",
    "\n",
    "# Load normalization statistics\n",
    "print(\"Loading normalization statistics...\")\n",
    "with open(data_dir / \"norm_stats.pkl\", 'rb') as f:\n",
    "    norm_stats = pickle.load(f)\n",
    "\n",
    "print(\"Normalization stats loaded for variables:\", list(norm_stats.keys()))\n",
    "\n",
    "# ----------------------------\n",
    "# Normalization helpers \n",
    "# ----------------------------\n",
    "def apply_normalization(data, method, norm_stats, var_base, resolution='lr_interp'):\n",
    "    \"\"\"Apply normalization method to data.\"\"\"\n",
    "    if method == 'none':\n",
    "        return data\n",
    "    \n",
    "    elif method == 'minmax_global':\n",
    "        data_min = norm_stats[var_base][resolution]['global_min']\n",
    "        data_max = norm_stats[var_base][resolution]['global_max']\n",
    "        return 2 * (data - data_min) / (data_max - data_min + 1e-8) - 1\n",
    "    \n",
    "    elif method == 'minmax_pixel':\n",
    "        data_min = norm_stats[var_base][resolution]['pixel_min']\n",
    "        data_max = norm_stats[var_base][resolution]['pixel_max']\n",
    "        return 2 * (data - data_min) / (data_max - data_min + 1e-8) - 1\n",
    "    \n",
    "    elif method == 'zscore_global':\n",
    "        data_mean = norm_stats[var_base][resolution]['global_mean']\n",
    "        data_std = norm_stats[var_base][resolution]['global_std']\n",
    "        return (data - data_mean) / (data_std + 1e-8)\n",
    "    \n",
    "    elif method == 'zscore_pixel':\n",
    "        data_mean = norm_stats[var_base][resolution]['pixel_mean']\n",
    "        data_std = norm_stats[var_base][resolution]['pixel_std']\n",
    "        return (data - data_mean) / (data_std + 1e-8)\n",
    "    \n",
    "    elif method == 'instance_zscore':\n",
    "        data_np = data.values if hasattr(data, 'values') else data\n",
    "        data_mean = np.mean(data_np, axis=(1, 2), keepdims=True)\n",
    "        data_std = np.std(data_np, axis=(1, 2), keepdims=True)\n",
    "        data_normalized = (data_np - data_mean) / (data_std + 1e-8)\n",
    "        return data_normalized\n",
    "    \n",
    "    elif method == 'instance_minmax':\n",
    "        data_np = data.values if hasattr(data, 'values') else data\n",
    "        data_min = np.min(data_np, axis=(1, 2), keepdims=True)\n",
    "        data_max = np.max(data_np, axis=(1, 2), keepdims=True)\n",
    "        data_normalized = 2 * (data_np - data_min) / (data_max - data_min + 1e-8) - 1\n",
    "        return data_normalized\n",
    "\n",
    "def denormalize_predictions(predictions, method, norm_stats, var_base, input_data=None):\n",
    "    \"\"\"Denormalize predictions back to original scale.\"\"\"\n",
    "    if method == 'none':\n",
    "        return predictions\n",
    "    \n",
    "    elif method == 'minmax_global':\n",
    "        hr_min = norm_stats[var_base]['hr']['global_min']\n",
    "        hr_max = norm_stats[var_base]['hr']['global_max']\n",
    "        return ((predictions + 1) / 2) * (hr_max - hr_min) + hr_min\n",
    "    \n",
    "    elif method == 'minmax_pixel':\n",
    "        hr_min = norm_stats[var_base]['hr']['pixel_min']\n",
    "        hr_max = norm_stats[var_base]['hr']['pixel_max']\n",
    "        return ((predictions + 1) / 2) * (hr_max - hr_min) + hr_min\n",
    "    \n",
    "    elif method == 'zscore_global':\n",
    "        hr_mean = norm_stats[var_base]['hr']['global_mean']\n",
    "        hr_std = norm_stats[var_base]['hr']['global_std']\n",
    "        return predictions * hr_std + hr_mean\n",
    "    \n",
    "    elif method == 'zscore_pixel':\n",
    "        hr_mean = norm_stats[var_base]['hr']['pixel_mean']\n",
    "        hr_std = norm_stats[var_base]['hr']['pixel_std']\n",
    "        return predictions * hr_std + hr_mean\n",
    "    \n",
    "    elif method == 'instance_zscore':\n",
    "        input_mean = np.mean(input_data, axis=(1, 2), keepdims=True)\n",
    "        input_std = np.std(input_data, axis=(1, 2), keepdims=True)\n",
    "        return predictions * input_std + input_mean\n",
    "    \n",
    "    elif method == 'instance_minmax':\n",
    "        input_min = np.min(input_data, axis=(1, 2), keepdims=True)\n",
    "        input_max = np.max(input_data, axis=(1, 2), keepdims=True)\n",
    "        return ((predictions + 1) / 2) * (input_max - input_min) + input_min\n",
    "\n",
    "# ----------------------------\n",
    "# Model evaluation\n",
    "# ----------------------------\n",
    "def evaluate_model(model_path, norm_method, dataset, test_period):\n",
    "    \"\"\"Evaluate a single model on a dataset.\"\"\"\n",
    "    print(f\"    Evaluating {norm_method}...\")\n",
    "    \n",
    "    # Load model\n",
    "    model = UNet(in_channels=1, out_channels=1, initial_features=32, depth=5, dropout=0.2)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Extract test data\n",
    "    lr_data_xr = dataset[var_lr].sel(time=slice(test_period[0], test_period[1]))\n",
    "    hr_data_xr = dataset[variable].sel(time=slice(test_period[0], test_period[1]))\n",
    "    \n",
    "    lr_data_raw = lr_data_xr.values\n",
    "    hr_data_raw = hr_data_xr.values\n",
    "    \n",
    "    # Apply normalization to input\n",
    "    lr_data_norm = apply_normalization(lr_data_xr, norm_method, norm_stats, var_base)\n",
    "    \n",
    "    # Ensure it's numpy\n",
    "    if hasattr(lr_data_norm, 'values'):\n",
    "        lr_data_norm = lr_data_norm.values\n",
    "    \n",
    "    # Predict in batches\n",
    "    batch_size = 32\n",
    "    n_samples = len(lr_data_norm)\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, n_samples, batch_size):\n",
    "            batch = lr_data_norm[i:i+batch_size]\n",
    "            batch_tensor = torch.tensor(batch, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "            \n",
    "            batch_pred = model(batch_tensor)\n",
    "            predictions.append(batch_pred.cpu().numpy())\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0).squeeze(1)\n",
    "    \n",
    "    # Denormalize predictions\n",
    "    predictions_denorm = denormalize_predictions(\n",
    "        predictions, norm_method, norm_stats, var_base, lr_data_raw\n",
    "    )\n",
    "    \n",
    "    return predictions_denorm, hr_data_raw, lr_data_raw\n",
    "\n",
    "# ----------------------------\n",
    "# Main evaluation loop\n",
    "# ----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUATING WIND SPEED (SFCWIND) MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for scenario_name, dataset in datasets.items():\n",
    "    print(f\"\\n{scenario_name.upper()} Scenario\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    test_period = test_periods[scenario_name]\n",
    "    scenario_results = {}\n",
    "    \n",
    "    # Get ground truth\n",
    "    hr_data = dataset[variable].sel(time=slice(test_period[0], test_period[1]))\n",
    "    lr_data = dataset[var_lr].sel(time=slice(test_period[0], test_period[1]))\n",
    "    time_coords = hr_data.time\n",
    "    lat_coords = hr_data.lat\n",
    "    lon_coords = hr_data.lon\n",
    "    \n",
    "    # Store ground truth and input\n",
    "    scenario_results['groundtruth'] = hr_data\n",
    "    scenario_results['input'] = lr_data\n",
    "    \n",
    "    # Evaluate each model\n",
    "    for norm_method in normalizations:\n",
    "        model_path = ckpt_dir / f\"sfcWind_{norm_method}.pth\"\n",
    "        \n",
    "        if not model_path.exists():\n",
    "            print(f\"Model not found: {model_path}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            predictions, groundtruth, inputs = evaluate_model(\n",
    "                model_path, norm_method, dataset, test_period\n",
    "            )\n",
    "            \n",
    "            pred_da = xr.DataArray(\n",
    "                predictions,\n",
    "                coords={'time': time_coords, 'lat': lat_coords, 'lon': lon_coords},\n",
    "                dims=['time', 'lat', 'lon'],\n",
    "                name=f'sfcWind_pred_{norm_method}'\n",
    "            )\n",
    "            \n",
    "            scenario_results[f'pred_{norm_method}'] = pred_da\n",
    "            print(f\"Success\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    all_results[scenario_name] = scenario_results\n",
    "\n",
    "# ----------------------------\n",
    "# Save results\n",
    "# ----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "output_dir = Path(\"evaluation_results\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for scenario_name, results in all_results.items():\n",
    "    ds_result = xr.Dataset()\n",
    "    \n",
    "    ds_result['groundtruth'] = results['groundtruth']\n",
    "    ds_result['input'] = results['input']\n",
    "    \n",
    "    for norm_method in normalizations:\n",
    "        key = f'pred_{norm_method}'\n",
    "        if key in results:\n",
    "            ds_result[key] = results[key]\n",
    "    \n",
    "    output_path = output_dir / f\"sfcWind_evaluation_{scenario_name}.nc\"\n",
    "    ds_result.to_netcdf(output_path)\n",
    "    print(f\"Saved: {output_path}\")\n",
    "\n",
    "print(\"\\nEvaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a96a0-3974-4904-9616-3010735cde4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26db45d0-5820-42b9-bd18-59dae3fc0a89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
