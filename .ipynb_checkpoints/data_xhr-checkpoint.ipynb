{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "736a4b4b-c60a-48d2-be53-bea466985f30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80bbce0d-26dc-4fbf-99a9-2ea954edf28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERA5:     ('time', 'lat', 'lon') (900, 721, 1440)\n",
      "HIST:     ('time', 'lat', 'lon') (900, 96, 192)\n",
      "G6:       ('time', 'lat', 'lon') (1032, 96, 192)\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Open datasets\n",
    "era5 = xr.open_dataset(\"data/era5/era5_t2m_1940-2014_monthly.nc\")\n",
    "hist = xr.open_dataset(\"data/cmip6/hist_lr_tas_monthly_1940_2014.nc\")\n",
    "g6sulfur = xr.open_dataset(\"data/cmip6/g6sulfur_lr_tas_monthly_2015_2100.nc\")\n",
    "\n",
    "# Extract DataArrays\n",
    "era5_t2m = era5['t2m']\n",
    "hist_tas = hist['tas']\n",
    "g6_tas = g6sulfur['tas']\n",
    "\n",
    "# --- Clean ERA5 ---\n",
    "era5_t2m = (era5_t2m\n",
    "    .rename({'valid_time': 'time', 'latitude': 'lat', 'longitude': 'lon'})\n",
    "    .drop_vars(['number', 'expver'], errors='ignore')\n",
    ")\n",
    "\n",
    "# --- Clean HIST ---\n",
    "hist_tas = (hist_tas\n",
    "    .drop_vars(['height', 'variant_label', 'sub_experiment_id'], errors='ignore')\n",
    ")\n",
    "\n",
    "# --- Clean G6SULFUR ---\n",
    "g6_tas = (g6_tas\n",
    "    .drop_vars(['height', 'variant_label', 'sub_experiment_id'], errors='ignore')\n",
    ")\n",
    "\n",
    "# --- Align time: use hist's time for era5 ---\n",
    "era5_t2m = era5_t2m.assign_coords(time=hist_tas.time)\n",
    "\n",
    "# Verify\n",
    "print(\"ERA5:    \", era5_t2m.dims, era5_t2m.shape)\n",
    "print(\"HIST:    \", hist_tas.dims, hist_tas.shape)\n",
    "print(\"G6:      \", g6_tas.dims, g6_tas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f425a38-311a-44e9-996e-57bdeba7bdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interpolating HIST...\n",
      "  Interpolating (900, 96, 192) to (721, 1440)...\n",
      "[########################################] | 100% Completed | 10.85 ss\n",
      "  Result shape: (900, 721, 1440)\n",
      "\n",
      "Interpolating G6SULFUR...\n",
      "  Interpolating (1032, 96, 192) to (721, 1440)...\n",
      "[########################################] | 100% Completed | 12.71 ss\n",
      "  Result shape: (1032, 721, 1440)\n",
      "\n",
      "Calculating residual (ERA5 - HIST_interp)...\n",
      "\n",
      "=== Final shapes ===\n",
      "ERA5:        (900, 721, 1440)\n",
      "HIST_interp: (900, 721, 1440)\n",
      "G6_interp:   (1032, 721, 1440)\n",
      "Residual:    (900, 721, 1440)\n",
      "\n",
      "=== Residual stats ===\n",
      "Mean: -0.059 K\n",
      "Std:  3.262 K\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "# Enable parallel computation\n",
    "dask.config.set(scheduler='threads', num_workers=64)\n",
    "\n",
    "# --- Bilinear interpolation (parallel) ---\n",
    "def interpolate_lr_to_hr_grid(lr_data, hr_lat, hr_lon, time_chunk_size=100):\n",
    "    \"\"\"Parallel bilinear interpolation to HR grid.\"\"\"\n",
    "    print(f\"  Interpolating {lr_data.shape} to ({len(hr_lat)}, {len(hr_lon)})...\")\n",
    "    \n",
    "    # Chunk along time dimension\n",
    "    lr_chunked = lr_data.chunk({'time': time_chunk_size})\n",
    "    \n",
    "    # Interpolate (lazy)\n",
    "    interpolated = lr_chunked.interp(\n",
    "        lat=hr_lat, \n",
    "        lon=hr_lon, \n",
    "        method='linear', \n",
    "        kwargs={'fill_value': 'extrapolate'}\n",
    "    )\n",
    "    \n",
    "    # Compute with progress bar\n",
    "    with ProgressBar():\n",
    "        result = interpolated.compute()\n",
    "    \n",
    "    print(f\"  Result shape: {result.shape}\")\n",
    "    return result\n",
    "\n",
    "# Get ERA5 target coordinates\n",
    "hr_lat = era5_t2m.lat\n",
    "hr_lon = era5_t2m.lon\n",
    "\n",
    "# Interpolate\n",
    "print(\"\\nInterpolating HIST...\")\n",
    "hist_interp = interpolate_lr_to_hr_grid(hist_tas, hr_lat, hr_lon)\n",
    "\n",
    "print(\"\\nInterpolating G6SULFUR...\")\n",
    "g6_interp = interpolate_lr_to_hr_grid(g6_tas, hr_lat, hr_lon)\n",
    "\n",
    "# --- Calculate residual ---\n",
    "print(\"\\nCalculating residual (ERA5 - HIST_interp)...\")\n",
    "residual = era5_t2m - hist_interp\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n=== Final shapes ===\")\n",
    "print(f\"ERA5:        {era5_t2m.shape}\")\n",
    "print(f\"HIST_interp: {hist_interp.shape}\")\n",
    "print(f\"G6_interp:   {g6_interp.shape}\")\n",
    "print(f\"Residual:    {residual.shape}\")\n",
    "\n",
    "# Residual stats\n",
    "print(\"\\n=== Residual stats ===\")\n",
    "print(f\"Mean: {float(residual.mean()):.3f} K\")\n",
    "print(f\"Std:  {float(residual.std()):.3f} K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e42e2bc-c482-4712-84da-b2d06b4c3222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data...\n",
      "Train period: 1940-01-16T12:00:00.000000000 to 2000-12-16T12:00:00.000000000\n",
      "Val period:   2001-01-16T12:00:00.000000000 to 2014-12-16T12:00:00.000000000\n",
      "Test period:  2015-01-16T12:00:00.000000000 to 2100-12-16T12:00:00.000000000\n",
      "\n",
      "Detrending inputs...\n",
      "  Train input...\n",
      "  Val input...\n",
      "  Test input (G6)...\n",
      "\n",
      "Computing normalization stats from training set...\n",
      "  Input detrend - mean range: [-0.00, 0.00]\n",
      "  Input detrend - std range:  [0.2839, 17.5948]\n",
      "  Residual - mean range: [-18.58, 13.12]\n",
      "  Residual - std range:  [0.3473, 7.6617]\n",
      "\n",
      "Saving normalization stats...\n",
      "\n",
      "Saving preprocessed data...\n",
      "\n",
      "=== Final shapes ===\n",
      "hist_train_detrend: (732, 721, 1440)\n",
      "hist_val_detrend:   (168, 721, 1440)\n",
      "g6_test_detrend:    (1032, 721, 1440)\n",
      "residual_train:     (732, 721, 1440)\n",
      "residual_val:       (168, 721, 1440)\n",
      "era5_train:         (732, 721, 1440)\n",
      "era5_val:           (168, 721, 1440)\n",
      "\n",
      "Done! All files saved.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# --- Define time splits ---\n",
    "train_slice = slice('1940', '2000')  # 1940-2000\n",
    "val_slice = slice('2001', '2014')    # 2001-2014\n",
    "\n",
    "# --- Split data ---\n",
    "print(\"Splitting data...\")\n",
    "\n",
    "# Inputs (to be detrended)\n",
    "hist_train = hist_interp.sel(time=train_slice)\n",
    "hist_val = hist_interp.sel(time=val_slice)\n",
    "g6_test = g6_interp  # already 2015-2100\n",
    "\n",
    "# Targets (NO detrending)\n",
    "residual_train = residual.sel(time=train_slice)\n",
    "residual_val = residual.sel(time=val_slice)\n",
    "\n",
    "# ERA5 (for reference)\n",
    "era5_train = era5_t2m.sel(time=train_slice)\n",
    "era5_val = era5_t2m.sel(time=val_slice)\n",
    "\n",
    "print(f\"Train period: {hist_train.time.values[0]} to {hist_train.time.values[-1]}\")\n",
    "print(f\"Val period:   {hist_val.time.values[0]} to {hist_val.time.values[-1]}\")\n",
    "print(f\"Test period:  {g6_test.time.values[0]} to {g6_test.time.values[-1]}\")\n",
    "\n",
    "# --- Detrend function (pixel-wise linear) ---\n",
    "def detrend_pixelwise(data):\n",
    "    \"\"\"Linear detrend at each grid point (following your example).\"\"\"\n",
    "    data_np = data.values\n",
    "    n_time, n_lat, n_lon = data_np.shape\n",
    "    \n",
    "    t = np.arange(n_time).astype(float)\n",
    "    t_mean = np.mean(t)\n",
    "    t_centered = t - t_mean\n",
    "    denominator = np.sum(t_centered**2)\n",
    "    \n",
    "    data_reshaped = data_np.reshape(n_time, -1)\n",
    "    data_mean = np.mean(data_reshaped, axis=0)\n",
    "    data_centered = data_reshaped - data_mean\n",
    "    \n",
    "    slopes = np.sum(t_centered[:, np.newaxis] * data_centered, axis=0) / denominator\n",
    "    intercepts = data_mean - slopes * t_mean\n",
    "    \n",
    "    trends = intercepts[np.newaxis, :] + slopes[np.newaxis, :] * t[:, np.newaxis]\n",
    "    detrended = (data_reshaped - trends).reshape(n_time, n_lat, n_lon)\n",
    "    \n",
    "    detrended_da = xr.DataArray(detrended, coords=data.coords, dims=data.dims)\n",
    "    \n",
    "    return detrended_da\n",
    "\n",
    "# --- Detrend inputs (separately for each split) ---\n",
    "print(\"\\nDetrending inputs...\")\n",
    "\n",
    "print(\"  Train input...\")\n",
    "hist_train_detrend = detrend_pixelwise(hist_train)\n",
    "\n",
    "print(\"  Val input...\")\n",
    "hist_val_detrend = detrend_pixelwise(hist_val)\n",
    "\n",
    "print(\"  Test input (G6)...\")\n",
    "g6_test_detrend = detrend_pixelwise(g6_test)\n",
    "\n",
    "# --- Compute normalization stats from TRAINING set only ---\n",
    "print(\"\\nComputing normalization stats from training set...\")\n",
    "\n",
    "def compute_pixel_stats(data):\n",
    "    \"\"\"Compute pixel-wise mean and std (over time).\"\"\"\n",
    "    return {\n",
    "        'mean': data.mean(dim='time').values,\n",
    "        'std': data.std(dim='time').values\n",
    "    }\n",
    "\n",
    "norm_stats_xhr = {\n",
    "    'input_detrend': compute_pixel_stats(hist_train_detrend),\n",
    "    'residual': compute_pixel_stats(residual_train),\n",
    "    'era5': compute_pixel_stats(era5_train),\n",
    "}\n",
    "\n",
    "print(f\"  Input detrend - mean range: [{norm_stats_xhr['input_detrend']['mean'].min():.2f}, {norm_stats_xhr['input_detrend']['mean'].max():.2f}]\")\n",
    "print(f\"  Input detrend - std range:  [{norm_stats_xhr['input_detrend']['std'].min():.4f}, {norm_stats_xhr['input_detrend']['std'].max():.4f}]\")\n",
    "print(f\"  Residual - mean range: [{norm_stats_xhr['residual']['mean'].min():.2f}, {norm_stats_xhr['residual']['mean'].max():.2f}]\")\n",
    "print(f\"  Residual - std range:  [{norm_stats_xhr['residual']['std'].min():.4f}, {norm_stats_xhr['residual']['std'].max():.4f}]\")\n",
    "\n",
    "# --- Save normalization stats ---\n",
    "print(\"\\nSaving normalization stats...\")\n",
    "with open('data/norm_stats_xhr.pkl', 'wb') as f:\n",
    "    pickle.dump(norm_stats_xhr, f)\n",
    "\n",
    "# --- Save preprocessed data ---\n",
    "print(\"\\nSaving preprocessed data...\")\n",
    "\n",
    "# CMIP6 folder - detrended inputs\n",
    "hist_train_detrend.to_netcdf('data/cmip6/hist_train_detrend_xhr.nc')\n",
    "hist_val_detrend.to_netcdf('data/cmip6/hist_val_detrend_xhr.nc')\n",
    "g6_test_detrend.to_netcdf('data/cmip6/g6_test_detrend_xhr.nc')\n",
    "\n",
    "# CMIP6 folder - interpolated (non-detrended)\n",
    "hist_train.to_netcdf('data/cmip6/hist_train_interp_xhr.nc')\n",
    "hist_val.to_netcdf('data/cmip6/hist_val_interp_xhr.nc')\n",
    "g6_test.to_netcdf('data/cmip6/g6_test_interp_xhr.nc')\n",
    "\n",
    "# ERA5 folder\n",
    "era5_train.to_netcdf('data/era5/era5_train_xhr.nc')\n",
    "era5_val.to_netcdf('data/era5/era5_val_xhr.nc')\n",
    "\n",
    "# Residuals\n",
    "residual_train.to_netcdf('data/era5/residual_train_xhr.nc')\n",
    "residual_val.to_netcdf('data/era5/residual_val_xhr.nc')\n",
    "\n",
    "# --- Summary ---\n",
    "print(\"\\n=== Final shapes ===\")\n",
    "print(f\"hist_train_detrend: {hist_train_detrend.shape}\")\n",
    "print(f\"hist_val_detrend:   {hist_val_detrend.shape}\")\n",
    "print(f\"g6_test_detrend:    {g6_test_detrend.shape}\")\n",
    "print(f\"residual_train:     {residual_train.shape}\")\n",
    "print(f\"residual_val:       {residual_val.shape}\")\n",
    "print(f\"era5_train:         {era5_train.shape}\")\n",
    "print(f\"era5_val:           {era5_val.shape}\")\n",
    "\n",
    "print(\"\\nDone! All files saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
